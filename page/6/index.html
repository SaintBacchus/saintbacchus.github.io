<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yoursite.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="A place for codeing break.">
<meta property="og:type" content="website">
<meta property="og:title" content="Carlmartin&#39; Blog">
<meta property="og:url" content="http://yoursite.com/page/6/index.html">
<meta property="og:site_name" content="Carlmartin&#39; Blog">
<meta property="og:description" content="A place for codeing break.">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Carlmartin">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://yoursite.com/page/6/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/6/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Carlmartin' Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Carlmartin' Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">In me the tiger sniffs the rose.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Carlmartin</p>
  <div class="site-description" itemprop="description">A place for codeing break.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">57</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/14/%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%BC%95%E5%AF%BC%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E6%83%A8%E6%A1%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/06/14/%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%BC%95%E5%AF%BC%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E6%83%A8%E6%A1%88/" class="post-title-link" itemprop="url">迭代器引导的序列化惨案</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-06-14 12:57:31" itemprop="dateCreated datePublished" datetime="2019-06-14T12:57:31+08:00">2019-06-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>今天2月份左右GATK的4.1版本发布, 经过测试目前版本的准确率相对于单机版本也有版本提高, 具体数值见下表</p>
<center>单机版GATK准确率表</center>

<div class="table-container">
<table>
<thead>
<tr>
<th>单机GATK</th>
<th>Precision</th>
<th>Sensitivity</th>
<th>F-measure</th>
</tr>
</thead>
<tbody>
<tr>
<td>SNP</td>
<td>98.90%</td>
<td>99.84%</td>
<td>99.37%</td>
</tr>
<tr>
<td>INDEL</td>
<td>97.20%</td>
<td>96.22%</td>
<td>96.71%</td>
</tr>
</tbody>
</table>
</div>
<center>分布式版GATK准确率表</center>

<div class="table-container">
<table>
<thead>
<tr>
<th>分布式GATK</th>
<th>Precision</th>
<th>Sensitivity</th>
<th>F-measure</th>
</tr>
</thead>
<tbody>
<tr>
<td>SNP</td>
<td>98.91%</td>
<td>99.84%</td>
<td>99.37%</td>
</tr>
<tr>
<td>INDEL</td>
<td>97.32%</td>
<td>96.84%</td>
<td>96.84%</td>
</tr>
</tbody>
</table>
</div>
<p>从图表上看, 虽然目前分布式GATK还是beta特性, 但是准确率已经和单机版很接近, 并且有部分还超越了.</p>
<center>单机版和分布式性能比较表</center>

<div class="table-container">
<table>
<thead>
<tr>
<th>对比项</th>
<th>单机版本</th>
<th>分布式版本</th>
</tr>
</thead>
<tbody>
<tr>
<td>耗时</td>
<td>48H</td>
<td>3.5H</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>测试数据来源: <a href="http://smash.cs.berkeley.edu/datasets.html">http://smash.cs.berkeley.edu/datasets.html</a></p>
</blockquote>
<p>但是, 新版本的GAKT遇到一个严重的BUG, 使用<code>ReadsPipelineSpark</code>的时候, 如果使用<code>hg38</code>的Reference就必然出现<code>StackOverflowError</code></p>
<blockquote>
<p>Bug reported @ <a href="https://github.com/broadinstitute/gatk/issues/5869">issues-5869</a></p>
</blockquote>
<h2 id="问题定位"><a href="#问题定位" class="headerlink" title="问题定位"></a>问题定位</h2><p>这个问题有一个麻烦点就是, 从异常栈只能看出是序列化的时候出问题了, 但无法定位哪一行出现的问题, 因此需要首先定界出问题的代码行.</p>
<h3 id="问题定界"><a href="#问题定界" class="headerlink" title="问题定界"></a>问题定界</h3><p>一般来说, 定界问题有两种:  Debug大法和Print大法. </p>
<p>Debug大法适合你已经对代码有一定的了解, 并有相应的测试用例支持, 这样做比较事半功倍. </p>
<p>而Print大法比较适合现在这种情况, 对GATK的源码不是很熟悉, 而且不知道如何构造简单用例复现问题的时候, 这个时候就在<code>ReadsPipelineSpark</code>的代码路径里面, 打满日志, 根据报错前的日志, 定界出错代码位置.</p>
<p>经过打印了解到, <code>StackOverflowError</code>发生在这个代码段之中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Broadcast&lt;Supplier&lt;AssemblyRegionEvaluator&gt;&gt; <span class="title function_">assemblyRegionEvaluatorSupplierBroadcast</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> JavaSparkContext ctx,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> HaplotypeCallerArgumentCollection hcArgs,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> SAMFileHeader header,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> String reference,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> Collection&lt;Annotation&gt; annotations)</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">Path</span> <span class="variable">referencePath</span> <span class="operator">=</span> IOUtils.getPath(reference);</span><br><span class="line">    <span class="keyword">final</span> <span class="type">String</span> <span class="variable">referenceFileName</span> <span class="operator">=</span> referencePath.getFileName().toString();</span><br><span class="line">    <span class="keyword">final</span> <span class="type">ReferenceSequenceFile</span> <span class="variable">taskReferenceSequenceFile</span> <span class="operator">=</span> taskReferenceSequenceFile(referenceFileName);</span><br><span class="line">    <span class="keyword">final</span> <span class="type">VariantAnnotatorEngine</span> <span class="variable">annotatorEngine</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">VariantAnnotatorEngine</span>(annotations,  hcArgs.dbsnp.dbsnp, hcArgs.comps, hcArgs.emitReferenceConfidence != ReferenceConfidenceMode.NONE, <span class="literal">false</span>);</span><br><span class="line">    <span class="keyword">return</span> assemblyRegionEvaluatorSupplierBroadcastFunction(ctx, hcArgs, header, taskReferenceSequenceFile, annotatorEngine);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的大致逻辑是比较清楚的, 就是<code>Driver</code>将一部分信息通过Spark的<code>广播机制</code>发布到<code>Executor</code>里面, 这个会有序列化的动作.</p>
<p>序列化的对象有: <code>hcArgs</code>,<code>header</code>,<code>taskReferenceSequenceFile</code>,<code>annotatorEngine</code>这四个, 具体是哪一个呢? </p>
<p>这时候祭出<code>Save-Load</code>大法, 将其中某个值设置null, 再一次次的尝试, 最后发现<code>taskReferenceSequenceFile</code>设置为null的时候, 代码能走过这段逻辑.</p>
<blockquote>
<p>当然SL大法在用的时候, 经常被自己的先验知识影响, 当时重点一直在怀疑<code>header</code>和<code>annotatorEngine</code>这两个字段, 一直没想到Reference会有问题, 绕了不少弯路, 因此SL一次的时间还是挺长的.</p>
</blockquote>
<h3 id="问题定位f"><a href="#问题定位f" class="headerlink" title="问题定位f"></a>问题定位f</h3><p>上面已经定位出来是<code>ReferenceSequenceFile</code>这个类导致的问题, 那么这个类的哪一部分出问题了呢? 这个时候就要用到Debug大法. </p>
<p>构造一次测试用例:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SparkContext sc;</span><br><span class="line"><span class="type">ReferenceSequenceFile</span> <span class="variable">ref</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">UserDefinedReferenceSequenceFile</span>()</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    sc.broadcast(ref)</span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    t.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>UserDefinedReferenceSequenceFile</code>里面不断将其中的字段加入进去, 最后发现以下代码片段导致整个<code>StackOverflowError</code>的问题:</p>
<p><div align=center><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/iterator_serializable/001.png" alt=""></p>
<p>就是这个<code>Iterator</code>在序列化的时候, 会不断的递归遍历, 导致栈溢出.<br><code>Iterator</code>的实现为<code>LinkedHashIterator</code>, 里面<code>LinkedHashMap.Entry</code>为一个二叉树, 因此, 需要真实序列化的, 就会不断去遍历整个二叉树, 导致问题整个.</p>
<p><div align=center><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/iterator_serializable/002.png" alt=""></p>
<p><div align=center><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/iterator_serializable/003.png" alt=""></p>
<h2 id="问题修复方案"><a href="#问题修复方案" class="headerlink" title="问题修复方案"></a>问题修复方案</h2><p>社区已经有解决的<a href="https://github.com/broadinstitute/gatk/pull/5950">方案</a>了,  总体的方式就是不要在<code>Driver</code>加载Reference文件, 而是放在<code>Executor</code>, 这样就能免去序列化的步骤. </p>
<blockquote>
<p>社区的问题目的是为了解决内存问题, 但实际上这个是序列化的问题. 此外实际运行的时候, 还有一个内存OMM的问题, 这个并不能够解决.</p>
</blockquote>
<h3 id="为什么这个问题值得记录"><a href="#为什么这个问题值得记录" class="headerlink" title="为什么这个问题值得记录"></a>为什么这个问题值得记录</h3><ul>
<li>首先, 迭代器模式竟然会出现<code>StackOverFlowError</code>, 这个真的没想到.</li>
<li>其次, 对于陌生代码的定位方式记录一下.</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/13/%E8%BD%AC-%E5%87%A0%E9%81%93%E6%8A%9B%E7%A1%AC%E5%B8%81%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/06/13/%E8%BD%AC-%E5%87%A0%E9%81%93%E6%8A%9B%E7%A1%AC%E5%B8%81%E9%97%AE%E9%A2%98/" class="post-title-link" itemprop="url">[转]几道抛硬币问题</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-06-13 21:35:05" itemprop="dateCreated datePublished" datetime="2019-06-13T21:35:05+08:00">2019-06-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%BD%AC%E8%BD%BD%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">转载文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p>首先说明转载, 本文转自<a href="https://www.raychase.net/3144">这里</a></p>
</blockquote>
<h3 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h3><blockquote>
<p>1、平均需要抛掷多少次硬币，才会首次出现连续的两个正面？</p>
</blockquote>
<p>假设连续两个正面的期望是 E，那么，先看第一次抛硬币：</p>
<ol>
<li>如果抛到反面，那么还期望抛 E 次，因为抛到反面完全没用，总数就期望抛 E+1</li>
<li>如果抛到正面，那么要看下一次，如果下一次也是正面，那抛硬币就结束了，总数是 2；如果下一次是反面，那么相当于重头来过，总数就期望抛 E+2</li>
</ol>
<p>于是可以得到如下关系式：</p>
<blockquote>
<p>E = 0.5(E+1) + 0.25*2 + 0.25(E+2)</p>
</blockquote>
<p>得到所求期望 E=6</p>
<p>现在把题目拓展，不是说“连续两个正面”，而是“连续 n 个正面”呢？</p>
<p>这个问题 Matrix67 有非常有趣的解答 <a href="http://www.matrix67.com/blog/archives/3638">《用数学解赌博问题不稀奇，用赌博解数学问题才牛 B》</a>，下面我简述一下：</p>
<p>假设有一个赌场，赌博的方式就是猜正反，每来一个玩家来的时候都只带了 1 元，每次都会全部下注，然后赌正面，庄家抛硬币，如果猜错就是全部输掉，如果赢了就得到下注的两倍，玩家会一直玩一直玩直到钱输光；而赌场老板会看，如果有人赢到 2^n 元，就下令关闭赌场。</p>
<p>于是直到 n 次正面朝上的情况发生，赌场关闭，只有最后那 n 个人才赚到了钱，最后一人得到了 2 元（没算成本价 1 元），倒数第二人是 4 元……倒数第 n 人是 2^n 元，所以，一共得到（等比数列求和）：</p>
<blockquote>
<p>2+4+8+…+2^n = 2*(1-2^n)/(1-2) = 2^(n+1) – 2</p>
</blockquote>
<p>赌场有多少钱流入，自然就有多少钱流出，所以到赌场倒闭，玩家赢得的钱的总数，就应该等于赌场期望的收入。而因为每个人来的时候都只带了 1 元，因此这个数正好等于期望的人数。于是这就是最终答案。</p>
<h3 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h3><blockquote>
<p>2、一堆硬币，每天都随便捡一枚抛，如果抛到正面，就把它翻过来；如果抛到反面，就再抛一下，问很长很长时间以后，硬币正面和反面的比例会趋近于多少？</p>
</blockquote>
<p>假设正面的比例是 x，那么反面就是 1-x，对于任意一次操作：</p>
<ul>
<li>如果抛到正面，那么得到的就一定是反面了；</li>
<li>如果抛到反面，那么得到正面的可能性为 0.5，反面的也为 0.5。</li>
</ul>
<p>所以得到正面的综合起来的概率为：</p>
<blockquote>
<p>x<em>0 + (1-x)</em>0.5 = x</p>
</blockquote>
<p>所以 x = 1/3，因此硬币正面和反面的比例会趋近于 x/(1-x) = 1/2</p>
<h3 id="问题三"><a href="#问题三" class="headerlink" title="问题三"></a>问题三</h3><blockquote>
<p>3、连续抛硬币，直到第一次出现连续两次正面为止，恰好抛了 N 次的概率是多少？</p>
</blockquote>
<p>考虑“恰好”抛 N 次硬币，到底有多少种情况可以得出最后两次是连续出现了正面，而之前没有出现过连续正面。</p>
<ul>
<li>假设 f(x) 表示第一次出现连续正面的时候，已经抛了 x 次，并且整个过程的第一次抛出的结果是反面；</li>
<li>假设 g(x) 表示第一次出现连续正面的时候，已经抛了 x 次，并且整个过程的第一次抛出的结果是正面。</li>
</ul>
<p>所以 f(1)=f(2)=0，g(1)=0，g(2)=1，而当 x&gt;2，</p>
<ul>
<li>求 f(x+1)，因为第一次是反面，所以这新添加的第一次不影响结果，因此 f(x+1)=f(x)+g(x)</li>
<li>求 g(x+1)，因为第一次是正面，必须要保证第二次不能为正，所以 g(x+1)=f(x)</li>
</ul>
<p>于是得到：</p>
<blockquote>
<p>f(x+2)=f(x+1)+g(x+1)=f(x+1)+f(x)</p>
<p>g(x+1)=f(x)</p>
</blockquote>
<p>其中，求 f(x) 的递推式可以看出 f(x) 是斐波那契数列，根据它的通项公式：</p>
<p><img src="https://www.raychase.net/wp-content/uploads/2015/07/coin-tossFibonacci_number.png" alt="Fibonacci_number"></p>
<p>得到 f(N)，也就得到了 g(N)，而总抛的可能性共有 2^N 次方，因此，概率为：</p>
<blockquote>
<p>(f(N)+g(N))/2^N</p>
</blockquote>
<h3 id="问题四"><a href="#问题四" class="headerlink" title="问题四"></a>问题四</h3><blockquote>
<p>4、抛硬币 N 次，出现连续 M 次正面的概率是多少？</p>
</blockquote>
<p>这个问题也很常见，但是做起来没那么容易，这里有一个 <a href="http://bbs.emath.ac.cn/thread-667-1-1.html">非常详细的讨论过程（链接）</a>，我就不搬过来了。</p>
<p>结果公式为: $\frac  {F^M_N} {2^N}$</p>
<h3 id="问题五"><a href="#问题五" class="headerlink" title="问题五"></a>问题五</h3><blockquote>
<p>5、抛 N 次硬币，正反两面出现次数相同的概率是多少？</p>
</blockquote>
<p>其实就是从 N 个硬币的空位中，选出 N/2 个作为正面，余下 N/2 个作为反面，应用组合公式可得到：</p>
<blockquote>
<p>C(N,N/2)/2^N=N!/((N-N/2)!(N/2)!)/2^N</p>
</blockquote>
<p>继续，</p>
<blockquote>
<p>正面出现次数超过反面的概率？</p>
</blockquote>
<p>因为正反情况相同，因此正面次数超过反面的概率应当等于反面次数超过正面的概率，因此结果为 1 减去上面那一问的结果之后除以 2：</p>
<blockquote>
<p>(1-C(N,N/2)/2^N)/2</p>
</blockquote>
<h3 id="MathJax公式书写规范"><a href="#MathJax公式书写规范" class="headerlink" title="MathJax公式书写规范"></a>MathJax公式书写规范</h3><p>$\frac {1 -  \frac {C{^N_{N/2}}} {2^N}}  2 \text {，mathjax最后计算公式示例}$</p>
<p>参考这篇<a href="https://www.jianshu.com/p/16fbd768bfe7">博客</a> 或者 <a href="https://www.zybuluo.com/codeep/note/163962">这篇</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/05/%E5%8A%A0%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/06/05/%E5%8A%A0%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/" class="post-title-link" itemprop="url">加解密技术</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-06-05 21:22:58" itemprop="dateCreated datePublished" datetime="2019-06-05T21:22:58+08:00">2019-06-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h2><p>本周在向组内培训安全编程规范的原则, 其中遇到了不少加解密算法相关的内容, 之前大致都了解过, 但是经常忘记, 因此今天特地写个博客把其中的内容都记录一下. </p>
<p>本片博客内容, 参考了不少<a href="https://songlee24.github.io/2015/05/03/public-key-and-private-key/">这篇文章</a>的内容,  有兴趣可以看原博客, 写的比我好.</p>
<h3 id="对称加密与非对称加密"><a href="#对称加密与非对称加密" class="headerlink" title="对称加密与非对称加密"></a>对称加密与非对称加密</h3><p><strong>对称加密</strong>使用同一个密钥进行加密和解密, 因此这个密钥是不能公开的, 那么密钥的分发就成了一个大问题, 如何在不受信任的网络之中分发密钥, 成为限制<strong>对称加密</strong>算法的痛点.</p>
<p>而<strong>非对称加密</strong>有两个密钥, 一个称之为<strong>公钥</strong>, 一个称之为<strong>私钥</strong>. <strong>公钥</strong>顾名思义可以在不受信任的网络之中分发, 无论攻击者是否获取了公钥都无法密文.</p>
<p><strong>非对称加密</strong>要实现这个能力, 需要有以下特点:</p>
<ol>
<li>公钥和私钥成对出现, 换而言之: <em>一把公钥有且只有一把私钥, 反之亦然</em></li>
<li>公钥加密的数据有且只能由对应的私钥解密, 反之亦然</li>
</ol>
<h3 id="非对称加密的传输过程"><a href="#非对称加密的传输过程" class="headerlink" title="非对称加密的传输过程"></a>非对称加密的传输过程</h3><ol>
<li><strong>接收方(解密者, 持有私钥)</strong> 生成一个密钥, 接收方将公钥广播给<strong>发送方(加密者, 持有公钥)</strong></li>
<li><strong>发送方</strong>将明文字符串安装某种字符串编码格式变成字节流</li>
<li><strong>发送方</strong>使用公钥对明文数据加密, 再将密文发送给<strong>接收方</strong></li>
<li><strong>接收方</strong>获得密文, 并使用私钥进行解密, 获得明文字节流</li>
<li><strong>接收方</strong>按照字符串编码格式加字节流解码为明文字符串</li>
</ol>
<p>整个步骤如下图所示(步骤一一对应): </p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/encrypt/20150502122610368.jpg" alt=""></p>
<p>已知在网络公开的数据有两种: 公钥和密文, 由于非对称算法的特性, 公钥无法对密文进行解密,  这样就保证了数据传输的安全性.</p>
<h3 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h3><p>签名, 顾名思义就是告诉别人, 这就是我.  在刚才<strong>非对称加密</strong>传输的例子是公钥持有者发送数据给私钥持有者, 如果反过来, 私钥持有者将数据加密之后发送给公钥持有者, 公钥持有者使用公钥解密数据, 这里由于公钥和数据都是公开的, 那么明文数据是什么已经不重要了, 重要的是<strong>这个文件就是私钥持有者加密的</strong>, 这个就是数字签名. </p>
<p>它通过非对称加密的原理, 由公钥来验证私钥持有者的身份, 防止密文内容被串改.</p>
<blockquote>
<p>当然公钥的安全性是先验的, 也就是说验证者必须知道自己公钥是什么, 而且公钥内容不能被攻击者篡改, 不然给了假的公钥和假的密文, 就往验证者系统注入一个受信内容.</p>
</blockquote>
<h3 id="非对称加密算法的缺点"><a href="#非对称加密算法的缺点" class="headerlink" title="非对称加密算法的缺点"></a>非对称加密算法的缺点</h3><p><strong>非对称加密算法</strong>的执行效率比<strong>对称加密算法</strong>慢了2-3个数量级, 如果用非对称加密算法去加密数据性能不能接受, 因此在实际上, 这两者一般结合起来一起使用.</p>
<p><strong>对称加密算法</strong>的缺点就是<strong>无法安全的传输密钥</strong>, 那么就由<strong>非对称加密算法</strong>传输密钥就好了:</p>
<ol>
<li><strong>接收方(持有非对称算法的私钥, 解密者)</strong>通过公钥机制生成一对密钥，一个公钥，一个私钥, 并发送给<strong>发送方(持有对称算法的密钥和非对称算法的公钥, 加密者)</strong></li>
<li><strong>发送方</strong>将明文字符串安装某种字符串编码格式变成字节流</li>
<li><strong>发送方</strong>使用非对称算法公钥对对称算法的密钥加密, 获得<strong>加密后的对称密钥</strong></li>
<li><strong>发送方</strong>使用对称加密的密钥对字节流进行加密</li>
<li><strong>发送方</strong>将3和4步骤的数据集编码之后发送给<strong>接收方</strong></li>
<li><strong>接收方</strong>拆分掉这两部分数据: <strong>加密后的对称密钥</strong> 和 <strong>密文</strong></li>
<li><strong>接收方</strong>用私钥进行解密得到对称算法的密钥。</li>
<li><strong>接收方</strong>再在用对称加密的密钥对原始的密文进行解密</li>
<li><strong>接收方</strong>按照字符串编码格式加字节流解码为明文字符串</li>
</ol>
<p>整个步骤如下图所示(步骤一一对应): </p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/encrypt/20150502122733376.jpg" alt=""></p>
<blockquote>
<p>这个图中, <strong>发送者</strong>和<strong>发送者</strong>只有两次交互, 这应该只是为了画图方便, 实际场景之中, 没必要将密钥和密文一起发送, 密文的传输应该就在其中握手过程完成.</p>
</blockquote>
<h3 id="常见的对称和非对称加密算法"><a href="#常见的对称和非对称加密算法" class="headerlink" title="常见的对称和非对称加密算法"></a>常见的对称和非对称加密算法</h3><p><strong>对称加密</strong>最常见的是AES和DES, 但是DES是一种弱加密算法, 不推荐使用<br><strong>不对称加密</strong>常见的有RSA/DSA/SHA256</p>
<p>秘钥的长度最低为:<br>AES: 128位<br>RSA: 2048位<br>DSA: 1024位<br>SHA: 256位</p>
<h2 id="非对称加密的数学原理"><a href="#非对称加密的数学原理" class="headerlink" title="非对称加密的数学原理"></a>非对称加密的数学原理</h2><iframe src="//player.bilibili.com/player.html?aid=26639065&cid=45813166&page=1" scrolling="no" border="0" frameborder="no" framespacing="0"  width="640" height="420" allowfullscreen="true"> </iframe>

<p>直接丟一个B站的视频, 李永乐老师对RSA算法讲解的非常通熟易懂, 一定要看一遍.</p>
<h2 id="HTTPS认证过程"><a href="#HTTPS认证过程" class="headerlink" title="HTTPS认证过程"></a>HTTPS认证过程</h2><blockquote>
<p>TBD</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/01/2019-06-01-%E5%86%8D%E7%9C%8B%E9%98%BF%E7%94%98%E6%AD%A3%E4%BC%A0%E6%9C%89%E6%84%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/06/01/2019-06-01-%E5%86%8D%E7%9C%8B%E9%98%BF%E7%94%98%E6%AD%A3%E4%BC%A0%E6%9C%89%E6%84%9F/" class="post-title-link" itemprop="url">[2019-06-01]再看阿甘正传有感</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-06-01 12:34:36" itemprop="dateCreated datePublished" datetime="2019-06-01T12:34:36+08:00">2019-06-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E9%9A%8F%E7%AC%94/" itemprop="url" rel="index"><span itemprop="name">随笔</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="缘由"><a href="#缘由" class="headerlink" title="缘由"></a>缘由</h2><p>前几天的时候, 看了&lt;阿甘正传&gt;的视频节目, 昨天晚上抽空又重温了一遍.  </p>
<p>说起来我已经有看过4遍的&lt;阿甘正传&gt;了:</p>
<ul>
<li>第一遍在高中时候看的, 那个时候觉得这个片子特别的爽, 毕竟是一个逆袭的故事嘛, 和大多数的网络小说的套路实际上类型. </li>
<li>第二遍是在大学的时候看的, 那个时候思绪关心政治历史哲学等内容, 特别关注于电影里面的历史进程, 觉得阿甘真的是历史见证者, 这也是另外一种意淫, 和大多数的穿越小说也类似.  </li>
<li>第三遍是在毕业之后看的, 那个时候关注电影的构建, 开始注意电影之中的人物塑造, 渐渐去了解了阿甘/珍妮/丹中尉/母亲等角色的性格</li>
<li>第四遍是昨天的看的, 发现了其中一个之前我一直没关注到的点: <strong>关于命运的思考</strong>. 在珍妮死去之后, 阿甘在墓前的那场戏, 实际上看着整部电影的文眼, 他让我思绪万千, 所以我就打算写个影评记录一下.</li>
</ul>
<h2 id="人物剖析"><a href="#人物剖析" class="headerlink" title="人物剖析"></a>人物剖析</h2><p>&lt;阿甘正传&gt;里面实际上描述的人物非常少,  因为整部电影都是以阿甘的视角展开的, 只有珍妮有一部分闪切的镜头来描述她的人生. 下面就依次描述一下对阿甘来说最重要的认.</p>
<h3 id="阿甘母亲"><a href="#阿甘母亲" class="headerlink" title="阿甘母亲"></a>阿甘母亲</h3><p>阿甘的口头禅是”妈妈曾经说过”, 说明他大部分的人生思考实际来自他妈妈,  她肯定是阿甘人生最重要的人.  她的形象应该是一个<strong>比较完美的乡下母亲</strong>, 当阿甘出生之后整个人生都围绕在阿甘身边:</p>
<ol>
<li><p>为让阿甘能上学而被潜规则</p>
</li>
<li><p>阿甘大学毕业之后, 以他为荣</p>
</li>
<li><p>尊重阿甘的人生选择, 并没有因为阿甘是低能儿而各种安排阿甘的人生.</p>
</li>
<li><p>耐心的教育阿甘, 特别是她死亡的时候那个场景, 能够那么平和的面对人生的结局, 并还在教育阿甘如何面对死亡/面对亲人的离去.  我自己有幻想今后如何教育自己的子女如何面对死亡, 因为这是一个无法逃避的问题, 我想阿甘母亲说的, 可能就是最好的注解了.</p>
</li>
</ol>
<p>阿甘的母亲在电影塑造上是非常 符号话的, 只有人物的形象, 并没有人物的血肉.</p>
<h3 id="丹中尉"><a href="#丹中尉" class="headerlink" title="丹中尉"></a>丹中尉</h3><p>这角色其实和阿甘母亲一样, 只是一个人物符号, 他是完全服务于电影另一个主题的表达: <strong>越战反思</strong>.<br>丹中尉出生一个电影的军人世家, 以为国牺牲为荣, 但是在越战之中受伤, 失去双腿, 身体残疾了; 国内反战严重, 不以军人为荣, 患上了PTSD, 精神也残疾了.<br>在现实之中, 他最大概率死于自杀, 但是由于&lt;阿甘正传&gt;属于正能量电影, 所以后面他正做起来了, 最后还娶了一个越南籍的老婆, 构成了对越战的反讽.</p>
<h3 id="珍妮"><a href="#珍妮" class="headerlink" title="珍妮"></a>珍妮</h3><p>珍妮是&lt;阿甘正传&gt;里面唯一有单独场景的人物(<em>其他人物都是和阿甘在一起的场景</em>) , 这个人物主要是为了与阿甘的人生做一个对比的, 象征着美国的两种完全不一样的思维方式.</p>
<p>阿甘是那种典型美国保守派的思路, 而珍妮是所谓的”垮掉的一代”的典型, 嬉皮士/反战/黑人运动, 哪儿有热闹就往哪儿钻. 她性解放/滥交/吸毒, 基本上所有传统道德反对的事情, 她都做.</p>
<p>但是最后阿甘和珍妮还是在一起了, 生下来了一个小阿甘, 因为阿甘和珍妮都是美国的一个象征, 一体两面. 最后以传统思维的胜利而结束, 因此珍妮就必须死去了, 但是留下了小阿甘, 代表了两种思潮合并后的现代美国, 继续生活下去了.</p>
<h3 id="阿甘"><a href="#阿甘" class="headerlink" title="阿甘"></a>阿甘</h3><p>和珍妮不同, 阿甘是所有美国保守派对于美好道德的憧憬: <strong>尽管人有缺陷, 但是道德是完美的</strong></p>
<p>阿甘在电影虽然戏份太多, 但是人物形象基本上很平, 首先是他是一个低能儿, 因此就不可能展现太多的思考, 其次电影太多的让阿甘的人生轨迹贴近历史了, 实际上对于他自身的心里描述很少. </p>
<p>前面的三个角色都是阿甘人生里面不可或缺的角色: </p>
<ol>
<li>母亲是阿甘人生的导师</li>
<li>丹中尉是阿甘的经济来源, 阿甘捕虾事业实际上由丹中尉再管理</li>
<li>珍妮是阿甘人生的追求和比对.</li>
</ol>
<h2 id="再论珍妮"><a href="#再论珍妮" class="headerlink" title="再论珍妮"></a>再论珍妮</h2><p>上面介绍珍妮的时候，完全是按照电影角色的角度去思考的，虽然我觉得编剧应该就是这么构想的，因为&lt;阿甘正传&gt;算商业电影，这么设计符合受众的口味．但是我决定还是<strong>过度解读</strong>一下, 以人的角度来描述. 珍妮就是珍妮, 阿甘就是阿甘, 他们是在那个时代阿拉巴马州的两个小镇孩子的缩影.</p>
<h3 id="少年期"><a href="#少年期" class="headerlink" title="少年期"></a>少年期</h3><p>阿甘是个笨蛋, 腿上又有点残疾, 但有一个非常爱他的母亲, 人虽然傻, 好在对世界的认识都很美好.</p>
<p>而珍妮是个正常人, 但出生在一个不正常家庭, 父亲小时候性侵她, 她最后报警搬到祖母的房车上居住, 她最大希望是逃离这个乡下, 逃离这个童年.</p>
<h3 id="青年期"><a href="#青年期" class="headerlink" title="青年期"></a>青年期</h3><p>阿甘凭借打橄榄球读了大学了, 并顺利毕业, 毕业后不知道去哪儿就去当兵, 然后去了越南打战.</p>
<p>珍妮在大学里开始就解放了天性, 梦想当一个歌手, 站在一个瞩目的位置, 但是命运弄人, 只能靠肉体在杂志里出位.</p>
<h3 id="越战期间"><a href="#越战期间" class="headerlink" title="越战期间"></a>越战期间</h3><p>阿甘就一路开挂, 而珍妮则在参加嬉皮士运动, 反战等, 这段期间可以珍妮已经放弃了人生, 随波逐流, 跟随那些进步青年的口号, 走上了国内战场.</p>
<h3 id="越战归来"><a href="#越战归来" class="headerlink" title="越战归来"></a>越战归来</h3><p>阿甘开始当上的捕虾船长, 而这个珍妮就真的堕落了, 开始吸毒当妓女, 生活一片黑暗, 甚至想寻死. 珍妮想跳楼的那场戏是塑造人物最重要的点, 让观众了解珍妮不只是享乐主义的人, 她有她自己痛苦, 而且这场戏也是她人生的一个转折点.</p>
<h3 id="母亲过世"><a href="#母亲过世" class="headerlink" title="母亲过世"></a>母亲过世</h3><p>阿甘母亲过世之后, 阿甘就又回归到小镇生活了, 而珍妮也厌倦了之前的生活, 回到阿甘身边生活了一段时间. 最后阿甘向珍妮求婚之后, 珍妮再一次离别.</p>
<h3 id="奔跑吧"><a href="#奔跑吧" class="headerlink" title="奔跑吧"></a>奔跑吧</h3><p>之后, 阿甘就开启了长跑之路, 而珍妮也开始回归正常生活, 当起来了单身母亲</p>
<h3 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h3><p>最后珍妮得病, 把小阿甘托付之后, 和阿甘结婚, 马上就过世了. 阿甘就独立带孩子, 完成新的一个轮循环.</p>
<h3 id="三次离别"><a href="#三次离别" class="headerlink" title="三次离别"></a>三次离别</h3><p>珍妮有三次和阿甘分道扬镳, 一次在越战之前, 一次在越战之后, 最后一次在小镇生活过一段时间之后.</p>
<p>第一次的时候, 两个人的追求不同, 珍妮希望当明星, 而阿甘没有追求</p>
<p>第二次的时候, 两个人的人生不同, 珍妮显然看不上阿甘甘于寂寞的人生.</p>
<p>第三次的时候, 两个人的经历不同, 珍妮有点看不起自己, 另外不想住在greenblow</p>
<h3 id="为什么要奔跑"><a href="#为什么要奔跑" class="headerlink" title="为什么要奔跑"></a>为什么要奔跑</h3><p>阿甘跑遍美国的时候, 一直解释说自己没有目的, 他确实很没有目的, 但又有目的: 阿甘母亲过世之前, 她一直是阿甘的精神支柱; 她过世之后, 珍妮就成了他人生的唯一意义, 当珍妮来到greenblow的时候, 阿甘觉得是这辈子最幸福的时候, 但当珍妮再次离开的时候, 他觉得整个人生的意义就不存在了. </p>
<p>其中有一场戏, 阿甘看着空空荡荡的房间, 看见珍妮留在房间的总统勋章, 演技是真的很好: 有一种心死了的感觉. 换一个正常的人, 可能会想着寻死觅活, 而阿甘想到就是珍妮的那句话, 跑.</p>
<h3 id="珍妮的悲剧"><a href="#珍妮的悲剧" class="headerlink" title="珍妮的悲剧"></a>珍妮的悲剧</h3><p>珍妮和阿甘的悲剧最大的原因在于, 珍妮是比较了解阿甘的, 但是阿甘是完全不了解珍妮的.</p>
<p>珍妮知道阿甘的痛苦: 当在电视里面看到阿甘在跑的时候, 珍妮就知道阿甘非常痛苦, 她知道阿甘为什么痛苦, 所以准备回到阿甘身边(<em>写信</em>), 也开始关注阿甘的动态(<em>剪报</em>) .</p>
<p>而阿甘不知道珍妮的痛苦: 珍妮朝老房子扔石头的时候, 阿甘是不知道为什么的, 到最后只知道珍妮讨厌老房子, 就把她推平了</p>
<h3 id="珍妮的救赎"><a href="#珍妮的救赎" class="headerlink" title="珍妮的救赎"></a>珍妮的救赎</h3><p>珍妮的人生悲剧在于那个悲惨的童年, 她一直想逃离, 但一直都无法逃离. 最后一个离开阿甘的时候, 说道”我没有逃”. 但是我觉得她确实不想逃了, 但是并没有完全放下: 她并不想住在小时候的地方, 而阿甘却一直想住在童年的地方. 所以她第三次的时候, 又逃离了.</p>
<p>而真正让珍妮放下的是, 她有了下一代, 当人有下一代的时候, 人的责任心就不一样了.</p>
<p>之前只想着自己的生活, 之后大多数的考虑都围绕在孩子在周围.</p>
<p><strong>有了下一代的含义, 就是这一代结束了</strong></p>
<p>当珍妮在剪报的时候, 她已经完成了救赎, 她结束了自己的使命.</p>
<h2 id="关于命运"><a href="#关于命运" class="headerlink" title="关于命运"></a>关于命运</h2><p>之前说过, 阿甘在珍妮的墓前说:</p>
<blockquote>
<p>这一切是命中注定的, 还是命运无常, 他觉得两者都有.</p>
</blockquote>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/gum/Selection_018.png" alt=""></p>
<p>这里主语不清楚, 我觉得他应该说的是他和珍妮的人生, 命中注定说的是结局, 命运无常说的是过程.</p>
<p>但我想说的是, 阿甘是命中注定, 而珍妮是命运无常.</p>
<p>阿甘虽然脑子不太好使, 但是有一个特别能跑的优点, 又有主角光环, 关键还有一个珍妮值得它去爱,  这三个优点无论去掉哪个, 阿甘的人生都暗淡的.</p>
<p>而珍妮虽然人长得漂亮, 但是出生于一个恶劣的家庭环境, 个人又没有明显的特长, 人生旅途之中又没有一个真正能拯救她的人, 唯一一个爱他的阿甘, 又根本无法了解她的内心, 可以说她一直都是孤独的.</p>
<p>站在珍妮的角度, 能死在阿甘的怀里, 可能已经是她最幸福的结局了. 她确实是一个可怜的人.</p>
<p><strong>命运是一种看不见摸不着的东西, 但你想摆脱它, 那又比登天一样难</strong></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>&lt;阿甘正传&gt;并非一部非常经得起分析的电影, 特别是关于人物方面的, 但是我还是推荐你们多去看几遍, 因为我知道大多数人是不会去看这种贴近历史的严肃文学的, 例如我看过的&lt;白鹿原&gt;, 也是以历史为背景介绍一个村子人的变化, 虽然着眼点很小, 但是里面的人物确实觉得是真实的人.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/08/GATK4-0-Spark%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2018/09/08/GATK4-0-Spark%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">GATK4.0 Spark性能分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-09-08 15:23:19" itemprop="dateCreated datePublished" datetime="2018-09-08T15:23:19+08:00">2018-09-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>这篇文章讲记录GATK4.0 Spark流程之中性能点的分析.<br>目前我们团队已经把整个参数调优已经做到了极致, 目前已经识别的这些性能优化点只能优化GATK代码方式去调优了, 这也是我们团队接下来的一个重要工作.</p>
<p>因此, 这篇文章讲包括:</p>
<ol>
<li>GATK步骤的主要瓶颈点</li>
<li>以及造成该瓶颈的原因</li>
<li>优化建议</li>
</ol>
<p>这篇文章不包括:</p>
<ol>
<li>具体的GATK调优的参数</li>
<li>具体的Spark调优的参数</li>
<li>GATK算法相关瓶颈点(目前能力不够, 以后有机会再分析)</li>
<li>GATK源码级调优</li>
</ol>
<h2 id="流程剖析"><a href="#流程剖析" class="headerlink" title="流程剖析"></a>流程剖析</h2><p>之前已经有介绍<a href="https://saintbacchus.github.io/2018/08/19/%E4%BD%BF%E7%94%A8Spark%E8%BF%9B%E8%A1%8CWGS%E5%88%86%E6%9E%90/">GATK4.0 Spark</a>的测序流程, 这里就按照里面的步骤一个一个分析吧.</p>
<p>分析的样本为NA12878的fastq.gz(98GB)文件, Ref使用HG38(3G), KnownSites使用GATK官网文件, 总大小为8G<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1000g_omni2.5.hg38.vcf</span><br><span class="line">1000g_phase1.snps.high_confidence.hg38.vcf</span><br><span class="line">dbsnp_144.hg38.vcf</span><br><span class="line">hapmap_3.3.hg38.vcf</span><br><span class="line">homo_sapiens_assembly38.known_indels.vcf</span><br><span class="line">mills_and_1000g_gold_standard.indels.hg38.vcf</span><br></pre></td></tr></table></figure></p>
<h3 id="FastqToSam"><a href="#FastqToSam" class="headerlink" title="FastqToSam"></a>FastqToSam</h3><p>由于FastQ文件是GZ格式的, 而Gzip格式在HDFS上是无法切分的, 因此无法用Spark加速, 所以实际上<code>FastqToSam</code>工具是单机的.<br>这个步骤主要耗时是花费在<code>fastq.gz</code>解压缩之中, 目前我们处理这个步骤需要花费90分钟, 而使用linux的命令解压缩单个文件大约就需要1个小时以上, 因此基本上只要解压缩完就能处理完毕</p>
<p><strong>现状瓶颈:</strong> fastq.gz的文件解压缩</p>
<p><strong>瓶颈原因:</strong> <code>FastqToSam</code>调用的是Java的GZip库进行解压的, 因此整个性能和linux gzip命令的性能一样. 而gzip解压缩最大的问题在于是单线程解压的, 因此性能一直不高, 而且机器的CPU利用率也非常低.</p>
<p><strong>优化建议:</strong> 实际上<code>fastq.gz</code>格式不是linux上那种通用的gzip格式, 而且专门为生物信息领域设计的gzip格式, 因此它实际上可以多线程解压的. 经过测试使用<a href="http://www.htslib.org/download/">bgzip</a>多线程解压, 性能可以从原有的1个小时, 提高到半个小时左右(4线程). 但是目前这个工具似乎只有C语言版本, <code>FastqToSam</code>是用java写的, 如果想利用这个步骤, 可能要用到JNI的技术来实现C语言的加载.</p>
<h3 id="BwaSpark"><a href="#BwaSpark" class="headerlink" title="BwaSpark"></a>BwaSpark</h3><p>首先看一样,<code>BwaSpark</code>的Spark的任务图<br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/gatk_perf/BwaSparkJobs.png" alt=""></p>
<p>总共有2个长时间的Job组成, 一个是<code>collect</code>,一个是<code>save</code></p>
<p>分析collect过程, 发现每个Task都很小, 绝大部分的时间加载Ref文件, 由于每个Executor都需要拉取5G左右的Ref文件, 当Executor达到50个以上的时候, 将近有250GB的数据需要在集群交互.</p>
<p>save过程, 是用BWA软件将每个小的Bam文件进行比对, 这个步骤目前无法优化.</p>
<p><strong>现状瓶颈:</strong> 获取HDFS数据慢</p>
<p><strong>瓶颈原因:</strong> 每个Executor都需要拉取5G左右的Ref, HDFS无法承受如此高的资源.</p>
<p><strong>优化建议:</strong> 提前加载Ref的Image的数据, 让整个流程快速开始计算.</p>
<h3 id="ReadsPipelineSpark"><a href="#ReadsPipelineSpark" class="headerlink" title="ReadsPipelineSpark"></a>ReadsPipelineSpark</h3><p>看一下, <code>ReadsPipelineSpark</code>的Spark的任务图<br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/gatk_perf/ReadsPipelineSpark_Jobs.png" alt=""></p>
<p>这个时间需要消耗在<code>BaseRecalibratorSpark</code>和<code>VariantsSparkSink</code>,前者是BQSR的计算流程, 后者是<code>HaplotypeCallerSpark</code>的流程.</p>
<p><code>HaplotypeCallerSpark</code>只消耗了32min符合预期, 但是BQSR流程耗时1.2小时, 时间慢的不正常.</p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/gatk_perf/BQSR_Jobs.png" alt=""><br>打开最慢的那个步骤的日志, 发现加载KnownSites文件将近耗费了25分钟, 整个流程被阻塞近半个小时.<br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/gatk_perf/BQSR_Logs.png" alt=""></p>
<p><strong>现状瓶颈:</strong> KnownSites文件加载过慢</p>
<p><strong>瓶颈原因:</strong> 每个Exeuctor都要计算并加载整个KnownSites</p>
<p><strong>优化建议:</strong> 提前加载KnownSites的数据, 让整个流程快速开始计算.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>目前对于Spark WGS流程的优化点, 有以下两个:</p>
<ol>
<li>使用bgzip加速FastQ转化Bam</li>
<li>将整个GATK作为Service, 提前加载好所有的资源文件, 客户端提交工具请求, 服务端直接开始计算. 作为完全的Serviceless的服务.</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/19/%E4%BD%BF%E7%94%A8Spark%E8%BF%9B%E8%A1%8CWGS%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2018/08/19/%E4%BD%BF%E7%94%A8Spark%E8%BF%9B%E8%A1%8CWGS%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">使用Spark进行WGS分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-08-19 19:03:03" itemprop="dateCreated datePublished" datetime="2018-08-19T19:03:03+08:00">2018-08-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="GATK简介"><a href="#GATK简介" class="headerlink" title="GATK简介"></a>GATK简介</h2><p>GATK全称叫做: Genome Analysis Toolkit. 是Broad Institute开发的用于二代重测序数据分析的一款软件.<br>目前主要用于人类的<strong>WGS</strong>以及<strong>WES</strong>基因测试流程, 具体流程介绍可以看官网的<a href="https://software.broadinstitute.org/gatk/best-practices/workflow?id=11145">最佳实践</a>  </p>
<p>GATK3版本之前, 一直都是单机版本, 性能一直是瓶颈点, 做完一个WGS的流程大约需要3天时间. 因此在GATK4以后的版本之中, 引入Spark做分布式性能优化, GATK4.0版本可以讲整个WGS测序流程的时间压缩在半天之内, 性能提高将近10倍有余.</p>
<p>但是, 目前所有标注有Spark加速的工具都是<code>BETA Tool</code>, 虽然就我们测试来看敏感度和准确性都和单机版本没有太大区别, 但是由于整理功能开发阶段, 工具接口可能会调整, 因此如果想应用到生产系统上的话, 也请慎重选择.</p>
<blockquote>
<p>WGS: Whole Genome Sequencing 全基因组测序</p>
<p>WES: Whole Exome Sequencing  全外显子测测序</p>
<h2 id="WGS流程简介"><a href="#WGS流程简介" class="headerlink" title="WGS流程简介"></a>WGS流程简介</h2><p>在GATK的最佳实践里面, 有流程介绍, 也有<a href="https://github.com/gatk-workflows/gatk4-germline-snps-indels">样例程序</a>供大家参考</p>
</blockquote>
<p>但是如果大家之前没有接触过WGS的话, 看官网的介绍还是有点晕. 推荐看一下<strong>碱基矿工</strong>的<a href="http://www.huangshujia.me/2018/02/20/2018-02-20-WGS-Best-Practics.html">GATK4.0和全基因组数据分析实践</a></p>
<p>好了, 言归正传, 我在这儿简单总结一下WGS的流程:  </p>
<ol>
<li>获取数据 — 脱机数据转化成FastQ格式</li>
<li>数据质控 — 使用<code>Fastqc</code>工具过滤掉低质量的数据</li>
<li>比对排序 — 使用<code>Bwa + samtools</code>工具对FastQ进行比对排序, 并将格式转化为Bam格式</li>
<li>碱基去重 — 使用GATK的<code>MarkDuplicates</code>工具完成该步骤</li>
<li>碱基矫正 — 使用GATK的<code>BQSR</code>工具完成该步骤</li>
<li>变异检测 — 使用GATK的<code>HaplotypeCaller</code>工具完成该步骤</li>
<li>变异控制 — 使用GATK的<code>VQSR</code>工具完成该步骤</li>
</ol>
<p>最后我们实现的一个功能是将原始的FastQ个数的数据, 转化为VCF格式的数据, 完成整个WGS的流程.</p>
<blockquote>
<p>VCF(Variant Call Format): 是种文本格式变异数据的格式, 可以直接用文本编辑器查看里面的字段及数据, 字段含义<a href="http://samtools.github.io/hts-specs/VCFv4.2.pdf">如文所示</a></p>
</blockquote>
<h2 id="使用Spark进行WGS分析流程"><a href="#使用Spark进行WGS分析流程" class="headerlink" title="使用Spark进行WGS分析流程"></a>使用Spark进行WGS分析流程</h2><h3 id="流程介绍"><a href="#流程介绍" class="headerlink" title="流程介绍"></a>流程介绍</h3><p>使用Spark进行WGS的流程如下图所示: </p>
<ol>
<li>首先FastQ格式的原始数据,通过<code>FastqToSam</code>工具转化为<code>UBam</code>格式</li>
<li>接着使用<code>BwaSpark</code>方法进行比对, 输出经过比对的<code>Bam</code>格式数据</li>
<li>最后通过<code>ReadsPipelineSpark</code>进行变异检测,并将变异点输出为<code>VCF</code>格式</li>
</ol>
<div id="flowchart-0" class="flow-chart"></div>

<p><strong>下面讲详细介绍每个工具的用法及命令</strong></p>
<h3 id="FastqToSam"><a href="#FastqToSam" class="headerlink" title="FastqToSam"></a>FastqToSam</h3><p><em>官网简介</em><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Converts a FASTQ file to an unaligned BAM or SAM file.</span><br><span class="line"></span><br><span class="line">Output read records will contain the original base calls and quality scores will be translated depending on the base quality score encoding: FastqSanger, FastqSolexa and FastqIllumina.</span><br><span class="line"></span><br><span class="line">There are also arguments to provide values for SAM header and read attributes that are not present in FASTQ (e.g see RG or SM below).</span><br></pre></td></tr></table></figure></p>
<p>这个工具的作用就是做好格式转化, 并对BAM格式进行排序. <strong>这个工具是单机的, 无法使用Spark加速. 官方工具转化一个NA1278 30X的样本大致需要3-4个小时. 我们团队这个工具进行了优化, 使得转化时间提高到1.5小时,大大降低了样本转化的时间</strong></p>
<p><em>执行命令</em><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/gatk/gatk FastqToSam -F1 NA12878_1.fastq.gz -F2 NA12878_2.fastq.gz -O NA12878_unaligned.bam -SM SM1 -PL illumina -R hg19.fa</span><br></pre></td></tr></table></figure></p>
<p><a href="https://software.broadinstitute.org/gatk/documentation/tooldocs/current/picard_sam_FastqToSam.php">FastqToSam文档</a></p>
<h3 id="BwaSpark"><a href="#BwaSpark" class="headerlink" title="BwaSpark"></a>BwaSpark</h3><p>简介<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Align reads to a given reference using BWA on Spark</span><br></pre></td></tr></table></figure></p>
<p>这个工具本质上是使用HDFS分片的能力, 让Spark对BWA软件分布化. Spark的每个Task都比对一个<em>块大小</em>的<code>uBam</code>. 每个块大小由参数<code>--bam-partition-size</code>指定, 默认值是使用Hadoop默认的块大小.<br><strong>通过Spark的分布式话, 原有的比对时间从4小时,可以降低到1个小时左右.</strong>  </p>
<p><em>执行命令</em><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/gatk/gatk BwaSpark -I hdfs://hacluster/gatk/NA12878_unaligned.bam -O hdfs://hacluster/gatk/NA12878_aligned.bam -R hdfs://hacluster/gatk/hg19.2bit --spark-runner SPARK --spark-master yarn-cluster</span><br></pre></td></tr></table></figure></p>
<p><a href="https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_spark_bwa_BwaSpark.php">BwaSpark文档</a></p>
<h3 id="ReadsPipelineSpark"><a href="#ReadsPipelineSpark" class="headerlink" title="ReadsPipelineSpark"></a>ReadsPipelineSpark</h3><p>简介<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Takes unaligned or aligned reads and runs BWA (if specified), MarkDuplicates, BQSR, and HaplotypeCaller to generate a VCF file of variants</span><br></pre></td></tr></table></figure></p>
<p>在之前的GATK版本之中, 每个命令都是单独的, 只能通过自己编写脚本的方式讲这些工具集串行起来.<br>而在GATK4.0之中, 想用<code>ReadsPipelineSpark</code>这一个工具, 将整个变异流程全部统一起来, 未来变异检测只要执行这个工具即可.   </p>
<blockquote>
<p>实际上<code>ReadsPipelineSpark</code>的流程能够包括<code>BwaSpark</code>的步骤, 但为什么还要特别分开呢? 原因在于: 目前<code>ReadsPipelineSpark</code>的实现之中没有缓存必要的RDD, 导致重计算, 整个性能没有分开计算好. 因此目前分成了两个步骤, 等社区解决了这个问题之后, 可以讲这两个步骤合并. 这也符合社区对于这个工具的定位.</p>
</blockquote>
<p><em>执行命令</em><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/gatk/gatk ReadsPipelineSpark -I hdfs://hacluster/gatk/NA12878_aligned.bam -O hdfs://hacluster/gatk/NA12878.vcf -R hdfs://hacluster/gatk/hg19.2bit --known-sites hdfs://hacluster/gatk_ref/dbsnp.vcf --spark-runner SPARK --spark-master yarn-cluster</span><br></pre></td></tr></table></figure></p>
<p><a href="https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_spark_pipelines_ReadsPipelineSpark.php">ReadsPipelineSpark文档</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>GATK4.0 在今年初引入了Spark进行分布式化性能优化, 整个WGS流程的性能由原有的<strong>天</strong>级别降低到<strong>小时</strong>级别, 性能得到极大优化.  </p>
<p>后续将从这个流程输出,分析一下目前使用Spark之中的性能瓶颈点以及源码级的分析</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="数据集获取"><a href="#数据集获取" class="headerlink" title="数据集获取"></a>数据集获取</h3><h4 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h4><p>输入的数据可以有两种, 一种是<a href="http://www.huangshujia.me/2017/08/12/2017-08-12-Begining-WGS-Data-Analysis-Fasta-And-Fastq.html">FASTQ</a>格式, 另外一种是<a href="http://www.huangshujia.me/2017/11/27/2017-11-27-Begining-WGS-Data-Analysis-BAM-CRAM-And-SAM.html">BAM</a>格式</p>
<blockquote>
<p>NA12878是人类基因测试里面最常用的实验数据</p>
<h4 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/Homo_sapiens_assembly38.fasta.gz</span><br><span class="line">wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/Homo_sapiens_assembly38.fasta.fai</span><br><span class="line">wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/Homo_sapiens_assembly38.fasta.64.alt</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="knownsites"><a href="#knownsites" class="headerlink" title="knownsites"></a>knownsites</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 获取SNP的Knownsites: 1000G_phase1.snps.high_confidence</span></span><br><span class="line">wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/1000G_phase1.snps.high_confidence.hg38.vcf.gz</span><br><span class="line">wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/1000G_phase1.snps.high_confidence.hg38.vcf.gz.tbi</span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取Indel的Knownsites: Mills_and_1000G_gold_standard.indels</span></span><br><span class="line">wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz</span><br><span class="line">wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz.tbi</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: Input(FastQ)
e=>end: Output(VCF)
op1=>operation: FastqToSam
op2=>operation: BwaSpark
op3=>operation: ReadsPipelineSpark

st->op1->op2->op3->e</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2015/10/30/Spark-Streaming-Indroduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2015/10/30/Spark-Streaming-Indroduce/" class="post-title-link" itemprop="url">Spark Streaming Indroduce</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2015-10-30 22:25:38" itemprop="dateCreated datePublished" datetime="2015-10-30T22:25:38+08:00">2015-10-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="面向人群"><a href="#面向人群" class="headerlink" title="面向人群"></a>面向人群</h3><ul>
<li>精通Java/Scala编程</li>
<li>Spark相关使用及编程经验</li>
<li>了解流应用架构</li>
</ul>
<hr>
<h3 id="简明介绍"><a href="#简明介绍" class="headerlink" title="简明介绍"></a>简明介绍</h3><p>Spark Streaming是一种基于微批量(<em>micro-batch</em>)方式计算和处理实时流数据执行框架。<br>Streaming依托于于Spark执行框架，将连续输入数据按批次切分，通过DStream(Discretized stream)来表征，然后按批次组装为Spark任务，放入Spark任务池中执行。<br><img src="http://spark.apache.org/docs/latest/img/streaming-flow.png" alt=""></p>
<center>图1 Streaming与Spark关系</center>

<p>因此基于<strong>micro-batch</strong>的Streaming必然会带有以下特征:</p>
<ul>
<li>高扩展性</li>
<li>高吞吐量</li>
<li>高可靠性</li>
<li>高延时性</li>
</ul>
<p>目前Streaming已经内置以下多种数据源和输出源的适配器，其中数据源使用比较多的是Kafka和HDFS，输出源一般都为HDFS。<br><img src="http://spark.apache.org/docs/latest/img/streaming-arch.png" alt="Streming输入输出"></p>
<center>图2 Streming输入输出</center>

<p>Streaming目前使用的案例并不是特别多，<a href="http://www.infoq.com/cn/news/2014/04/spark-streaming-bidding">Sharethrough</a>和<a href="http://www.infoq.com/cn/news/2015/04/pinterest-memsql-spark-streaming">Pinterest</a>是比较明确Streaming的使用者:).</p>
<h3 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h3><!-- 架构层设计 -->
<h4 id="micro-batch"><a href="#micro-batch" class="headerlink" title="micro-batch"></a>micro-batch</h4><p><img src="http://image.slidesharecdn.com/apachestormvs-140811162542-phpapp01/95/apache-storm-vs-spark-streaming-11-638.jpg?cb=1425908462" alt=""></p>
<center>图3 micro-batch与流与批的关系</center>

<p>Wiki上并没有关于<code>micro-batch</code>的介绍，甚至在Streaming的paper中也没有提出这个名词，只能从网上别人总结的图来说明。<br>用这个概念能很好的总结Spark Streaming的执行流程，也能很直观的与类似Storm这类<code>Record By Record</code>类型的流系统区别开来。所谓的<code>micro-batch</code>，它的本质是批处理，因此Streaming的执行层是Spark——一个批处理系统：</p>
<blockquote>
<p>Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs.</p>
</blockquote>
<p>因此，Streaming会天然继承Spark的优点：<em>高扩展性</em>、<em>高吞吐量</em>和<em>高可靠性</em>。<br>但是Streaming能够处理处理流式数据的原因在与它的batch相对于正常的Spark应用是非常小的，而且是严格按照时间切分批次。<br><strong>定义：</strong></p>
<blockquote>
<p>Streaming将流式数据分为多个<strong>固定时间窗口</strong>中的<strong>单批数据</strong>，并根据<strong>处理逻辑</strong>封装成Spark任务<strong>持续不断</strong>放入Spark中执行。  </p>
</blockquote>
<h4 id="JobGenerator"><a href="#JobGenerator" class="headerlink" title="JobGenerator"></a>JobGenerator</h4><p>Streaming需要提供按照<strong>固定时间</strong>产生的<strong>持续不断</strong>的Spark任务，因此在它的实现里，必然会有一个定时器，该定时器每隔<strong>固定时间</strong>生成一个处理该时间窗口数据的Spark任务，我们称这个组件为JobGenerator。<br>由于一些Streaming任务前后数据之间没有关联性，因此在JobGenerator中必须提供一个Spark的任务池，用于多线程的执行Spark的任务。</p>
<h4 id="Receiver"><a href="#Receiver" class="headerlink" title="Receiver"></a>Receiver</h4><p>Streaming还需要负责接收<strong>固定时间</strong>产生的流式数据，并将这种数据封装为JobGenerator产生Spark任务的输入数据，我们称之为Receiver。<br>由于<em>micro-batch</em>方式，Streaming可以同时处理批数据和流式数据，因此也会存在两种组织形式的Receiver。</p>
<ul>
<li>流式数据<br>以SocketReceiver为代表，通过单节点接受流式数据，将数据按批组装为任务输入数据，包括KafkaReceiver、FlumeReceiver等接收型数据。</li>
<li>批数据<br>以HDFS接口为代表，本身底层数据系统即是分布式数据，数据不需要组装，可以直接被RDD表征，在Streaming主要包括HDFS文件以及DirectKafkaAPI。</li>
</ul>
<h4 id="DStreamGraph"><a href="#DStreamGraph" class="headerlink" title="DStreamGraph"></a>DStreamGraph</h4><p>Streaming的API设计与<code>RDD</code>接口相似，RDD通过<code>dependencies_</code>存储自己的处理逻辑，并通过<code>DAGScheduler</code>分解出RDD整个Spark执行的逻辑，而相对应的<code>DStream</code>需要将自己的逻辑<em>翻译</em>为RDD原语，这个翻译过程被称为<code>DStreamGraph</code>。</p>
<p><img src="http://images.cnitblog.com/blog/287057/201404/231432212018837.jpg" alt=""></p>
<center>图4 DStream转化RDD</center>


<!-- API层设计 -->
<h4 id="DStream"><a href="#DStream" class="headerlink" title="DStream"></a>DStream</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Iter</span></span><br><span class="line"><span class="type">Source</span>.fromFile(<span class="string">&quot;&quot;</span>).getLines().flatMap(_.split(<span class="string">&quot;,&quot;</span>)).map(x =&gt; (x, <span class="number">1</span>)).foreach(println)</span><br><span class="line"><span class="comment">// RDD</span></span><br><span class="line"><span class="type">SpoarkContext</span>.textFile(<span class="string">&quot;&quot;</span>).flatMap(_.split(<span class="string">&quot;,&quot;</span>)).map(x =&gt; (x, <span class="number">1</span>)).foreach(println)</span><br><span class="line"><span class="comment">// DStream</span></span><br><span class="line"><span class="type">StreamingContext</span>.textFileStream(<span class="string">&quot;&quot;</span>).flatMap(_.split(<span class="string">&quot;,&quot;</span>)).map(x =&gt; (x, <span class="number">1</span>)).foreach(println)</span><br></pre></td></tr></table></figure>
<p>从上诉代码上看，DStream和RDD的接口都参考Scala的集合API设计，我们可以将迭代器理解为单机上表征数据以及数据转化方式的对象，那么从RDD的定义和实现来看，RDD是在分布式维度上表征数据及数据转化方式的对象。<br><strong>RDD定义：</strong></p>
<blockquote>
<p>Resilient Distributed Datasets (RDDs) are fault-tolerant, parallel data structures that let users explicitly persist intermediate results in memory, control their partitioning to optimize data placement, and manipulate them using a rich set of operators.</p>
</blockquote>
<p>而DStream可以理解为在时间维度上表征分布式数据及数据转化方式的对象：</p>
<blockquote>
<p>A discretized stream or D-Stream groups together <strong>a series of RDDs</strong> and lets the user manipulate them to through various operators. D-Streams provide both stateless operators, such as map, which act independently on each time interval, and stateful operators, such as aggregation over a sliding window, which operate on multiple intervals and may produce intermediate RDDs as state.   </p>
</blockquote>
<p>当然，DStream除了上述和scala集合操作对应的API，DStream还包括一些流应用特有的操作，例如</p>
<ul>
<li><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html#updatestatebykey-operation">updateStateByKey</a></li>
<li><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html#window-operations">Window Operations</a></li>
<li><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html#transform-operation">transform operation</a></li>
</ul>
<h3 id="实现浅析"><a href="#实现浅析" class="headerlink" title="实现浅析"></a>实现浅析</h3><h3 id="流式语义"><a href="#流式语义" class="headerlink" title="流式语义"></a>流式语义</h3><p>Streaming的语义在<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html#definitions">官网</a>已经有所介绍，总结而言：</p>
<ul>
<li>数据接收阶段，对于批数据已经实现<code>Exactly once</code>语义，对于流式数据在Spark-1.2以后引入<code>WAL</code>技术，可以保证<code>at-least once</code>语义</li>
<li>数据转化阶段，依托RDD的可靠性保证，Streaming能保证<code>Exactly once</code>语义</li>
<li>数据输出阶段，默认的语义只为<code>at-least once</code>，需要用户自己实现<code>Exactly once</code>语义</li>
</ul>
<h3 id="简单案例"><a href="#简单案例" class="headerlink" title="简单案例"></a>简单案例</h3><h4 id="HdfsWordCount"><a href="#HdfsWordCount" class="headerlink" title="HdfsWordCount"></a>HdfsWordCount</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;HdfsWordCount&quot;</span>)</span><br><span class="line"><span class="comment">// Create the context</span></span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the FileInputDStream on the directory and use the</span></span><br><span class="line"><span class="comment">// stream to count words in new files created</span></span><br><span class="line"><span class="keyword">val</span> lines = ssc.textFileStream(args(<span class="number">0</span>))</span><br><span class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"><span class="keyword">val</span> wordCounts = words.map(x =&gt; (x, <span class="number">1</span>)).reduceByKey(_ + _)</span><br><span class="line">wordCounts.print()</span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure>
<h4 id="DirectKafkaWordCount"><a href="#DirectKafkaWordCount" class="headerlink" title="DirectKafkaWordCount"></a>DirectKafkaWordCount</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;DirectKafkaWordCount&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create direct kafka stream with brokers and topics</span></span><br><span class="line"><span class="keyword">val</span> topicsSet = topics.split(<span class="string">&quot;,&quot;</span>).toSet</span><br><span class="line"><span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">&quot;metadata.broker.list&quot;</span> -&gt; brokers)</span><br><span class="line"><span class="keyword">val</span> messages = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](</span><br><span class="line">  ssc, kafkaParams, topicsSet)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Get the lines, split them into words, count the words and print</span></span><br><span class="line"><span class="keyword">val</span> lines = messages.map(_._2)</span><br><span class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line"><span class="keyword">val</span> wordCounts = words.map(x =&gt; (x, <span class="number">1</span>L)).reduceByKey(_ + _)</span><br><span class="line">wordCounts.print()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Start the computation</span></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure>
<p>Streaming应用一般有以下步骤：</p>
<ol>
<li>根据不同数据源接口获取<code>InputDStream</code>，对于Kafka即<code>KafkaUtils.createDirectStream</code>，对于HDFS即：<code>ssc.textFileStream</code></li>
<li>通过<code>DStream</code>接口根据业务对<code>InputDStream</code>进行转化：<code>flatMap(_.split(&quot; &quot;)).map(x =&gt; (x, 1L)).reduceByKey(_ + _)</code></li>
<li><code>DStream</code>输出结果，<code>print</code>和<code>saveAsTextFiles</code>等，如果需要自定义的输出结果，可以使用<code>foreachRDD</code>算子</li>
<li>调用<code>ssc.start()</code>和<code>ssc.awaitTermination()</code>，启动Streaming的计算</li>
</ol>
<p><strong>任务提交</strong><br>使用常规的Spark任务提交应用，例如<code>HdfsWordCount</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/run-example streaming.HdfsWordCount /streaming</span><br></pre></td></tr></table></figure><br>启动任务后，可以在本地上传文本文件到HDFS指定目录下，这时在日志界面上就能看到统计出来的单词条数<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hadoop fs -put textFie /streaming</span><br></pre></td></tr></table></figure></p>
<h3 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h3><p>公司案例</p>
<h3 id="学习建议"><a href="#学习建议" class="headerlink" title="学习建议"></a>学习建议</h3><ol>
<li>首先仔细浏览官网上<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Streaming编程指南</a>，学习Streaming相关概念</li>
<li>通过官方<a href="https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples/streaming">样例工程</a>熟悉API接口，并编写编写简单的应用，尝试在集群中运行。</li>
<li>学有余力的可以开始阅读Streaming源代码，并通过对比代码尝试定位运行过程中出现的问题。</li>
<li>学习<a href="http://kafka.apache.org/">Kafka</a>相关概念与架构以及其他流式组件</li>
<li>学习<a href="http://storm.apache.org/">其他流式</a>组件，集思广益</li>
</ol>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol>
<li><a href="https://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf">Spark Paper</a></li>
<li><a href="https://people.csail.mit.edu/matei/papers/2012/hotcloud_spark_streaming.pdf">Spark Streaming Paper</a></li>
<li><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Streaming Programming Guide</a></li>
<li><a href="http://stanford.edu/~rezab/sparkclass/slides/td_streaming.pdf">Indroduce By Tathagata</a></li>
<li><a href="http://www.csdn.net/article/2014-01-27/2818282-Spark-Streaming-big-data">大规模流式数据处理的新贵</a></li>
<li><a href="http://www.slideshare.net/ptgoetz/apache-storm-vs-spark-streaming">Storm与Spark Streaming比较</a></li>
<li><a href="http://www.cnblogs.com/shenh062326/p/3530092.html">Spark Streaming实时计算框架介绍</a></li>
<li><a href="http://blog.csdn.net/anzhsoft/article/details/38168025">从Storm和Spark 学习流式实时分布式计算的设计</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/5/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Carlmartin</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">186k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">2:49</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
