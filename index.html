<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yoursite.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="A place for codeing break.">
<meta property="og:type" content="website">
<meta property="og:title" content="Carlmartin&#39; Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Carlmartin&#39; Blog">
<meta property="og:description" content="A place for codeing break.">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Carlmartin">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://yoursite.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Carlmartin' Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Carlmartin' Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">In me the tiger sniffs the rose.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Carlmartin</p>
  <div class="site-description" itemprop="description">A place for codeing break.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">57</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/15/Hexo%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E8%AE%B0%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/06/15/Hexo%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E8%AE%B0%E5%BD%95/" class="post-title-link" itemprop="url">Hexo使用技巧记录</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-06-15 15:16:28" itemprop="dateCreated datePublished" datetime="2019-06-15T15:16:28+08:00">2019-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 17:02:49" itemprop="dateModified" datetime="2024-03-06T17:02:49+08:00">2024-03-06</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="新环境初始化"><a href="#新环境初始化" class="headerlink" title="新环境初始化"></a>新环境初始化</h2><blockquote>
<p>用于新环境的安装, 例如刚申请了一个电脑, 假设你配置完毕git和下载安装完毕<a href="http://nodejs.cn/download/">NodeJs</a></p>
</blockquote>
<p>执行下面的命令, 完成初始化命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:SaintBacchus/hexo.git</span><br><span class="line"><span class="built_in">cd</span> hexo</span><br><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure></p>
<h2 id="如何实现置顶功能"><a href="#如何实现置顶功能" class="headerlink" title="如何实现置顶功能"></a>如何实现置顶功能</h2><p>首先安装hexo插件:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-generator-index --save</span><br><span class="line">npm install hexo-generator-index-pin-top --save</span><br></pre></td></tr></table></figure>
<p>然后在文章的Front-matter头部加入:    <code>top: true</code></p>
<blockquote>
<p>出自<a href="http://wangwlj.com/2018/01/09/blog_pin_post/">博客</a></p>
</blockquote>
<h2 id="如何实现一个文章多个categories"><a href="#如何实现一个文章多个categories" class="headerlink" title="如何实现一个文章多个categories"></a>如何实现一个文章多个categories</h2><p>多个categories<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">categories:</span></span><br><span class="line">  <span class="bullet">-</span> [<span class="string">Sports</span>]</span><br><span class="line">  <span class="bullet">-</span> [<span class="string">Baseball</span>]</span><br></pre></td></tr></table></figure></p>
<p>多级categories<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">categories:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Sports</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Baseball</span></span><br></pre></td></tr></table></figure><br>或者<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">categories:</span> [<span class="string">Sports</span>,<span class="string">Baseball</span></span><br></pre></td></tr></table></figure></p>
<p>组合使用:<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">categories:</span></span><br><span class="line">  <span class="bullet">-</span> [<span class="string">Sports</span>,<span class="string">Baseball</span>]</span><br><span class="line">  <span class="bullet">-</span> [<span class="string">Play</span>]</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>出自<a href="http://aiellochan.com/2018/02/13/hexo/Hexo-%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%E5%A4%9A%E4%B8%AA-categories/">博客</a></p>
</blockquote>
<h2 id="文章加密"><a href="#文章加密" class="headerlink" title="文章加密"></a>文章加密</h2><p>使用如下命令安装:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-blog-encrypt</span><br></pre></td></tr></table></figure>
<p>启动插件, 在根<code>_config.yaml</code>设置:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Security</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="attr">encrypt:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>在每篇文章的Format里面设置:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># password: 是该博客加密使用的密码</span></span><br><span class="line"><span class="attr">password:</span> <span class="string">Mike</span></span><br><span class="line"><span class="comment"># abstract: 是该博客的摘要，会显示在博客的列表页</span></span><br><span class="line"><span class="attr">abstract:</span> <span class="string">Welcome</span> <span class="string">to</span> <span class="string">my</span> <span class="string">blog,</span> <span class="string">enter</span> <span class="string">password</span> <span class="string">to</span> <span class="string">read.</span></span><br><span class="line"><span class="comment"># message: 这个是博客查看时，密码输入框上面的描述性文字</span></span><br><span class="line"><span class="attr">message:</span> <span class="string">Welcome</span> <span class="string">to</span> <span class="string">my</span> <span class="string">blog,</span> <span class="string">enter</span> <span class="string">password</span> <span class="string">to</span> <span class="string">read.</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>出自<a href="https://github.com/MikeCoder/hexo-blog-encrypt/blob/master/ReadMe.zh.md">Github</a></p>
</blockquote>
<h2 id="绑定域名"><a href="#绑定域名" class="headerlink" title="绑定域名"></a>绑定域名</h2><blockquote>
<p>出自<a href="https://www.jianshu.com/p/514c7792ad10">简书</a></p>
</blockquote>
<h2 id="支持HTTPS认证"><a href="#支持HTTPS认证" class="headerlink" title="支持HTTPS认证"></a>支持HTTPS认证</h2><blockquote>
<p>出自<a href="https://molunerfinn.com/hexo-travisci-https/#%E5%8A%A0%E5%85%A5HSTS%E7%9A%84%E5%88%97%E8%A1%A8">博客</a></p>
</blockquote>
<h2 id="升级Hexo客户端"><a href="#升级Hexo客户端" class="headerlink" title="升级Hexo客户端"></a>升级Hexo客户端</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br><span class="line">hexo -v</span><br><span class="line">npm update</span><br></pre></td></tr></table></figure>
<h2 id="升级依赖"><a href="#升级依赖" class="headerlink" title="升级依赖"></a>升级依赖</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">npm install -g npm-check</span><br><span class="line">npm-check</span><br><span class="line">npm install -g npm-upgrade</span><br><span class="line">npm-upgrade</span><br><span class="line">npm update -g</span><br><span class="line">npm update --save</span><br></pre></td></tr></table></figure>
<h2 id="图片居中显示"><a href="#图片居中显示" class="headerlink" title="图片居中显示"></a>图片居中显示</h2><p>在图谱插入的前面加入HTML前缀<code>&lt;div align=center&gt;</code>, 使用方式如下:<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;div align=center&gt;![](https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/hexo/images/aboutme/1.png)</span><br></pre></td></tr></table></figure></p>
<h2 id="修改默认Front-matter"><a href="#修改默认Front-matter" class="headerlink" title="修改默认Front-matter"></a>修改默认Front-matter</h2><p>在根目录下有<code>/scaffolds/post.md</code>的文件用来定义默认的文章格式</p>
<p>在此键入以下模板</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> &#123;&#123; <span class="string">title</span> &#125;&#125;</span><br><span class="line"><span class="attr">date:</span> &#123;&#123; <span class="string">date</span> &#125;&#125;</span><br><span class="line"><span class="attr">tags:</span></span><br><span class="line"><span class="attr">categories:</span></span><br><span class="line"><span class="attr">typora-root-url:</span> <span class="string">..</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/03/04/Clickhouse%E7%A0%94%E7%A9%B6-TooManyPart%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/03/04/Clickhouse%E7%A0%94%E7%A9%B6-TooManyPart%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF/" class="post-title-link" itemprop="url">[Clickhouse研究]: TooManyPart问题解决思路</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-03-04 15:26:46" itemprop="dateCreated datePublished" datetime="2022-03-04T15:26:46+08:00">2022-03-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h1> <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">2021-12-08 10:20:52,561 ERROR org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat [] - JDBC executeBatch error, retry times = 1</span><br><span class="line">org.apache.flink.streaming.connectors.clickhouse.shaded.ru.yandex.clickhouse.except.ClickHouseException: ClickHouse exception, code: 252, host: 10.88.129.186, port: 8024; Code: 252, e.displayText() = DB::Exception: Too many parts (315). Merges are processing significantly slower than inserts.: while write prefix to view Storage omega_analyse_project_stream.dwm_log_pub_event_pvuv_hi_view_local (version 206.1.1)</span><br><span class="line"> </span><br><span class="line">    at org.apache.flink.streaming.connectors.clickhouse.shaded.ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:59) ~[flink-connector-clickhouse_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.streaming.connectors.clickhouse.shaded.ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:29) ~[flink-connector-clickhouse_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.streaming.connectors.clickhouse.shaded.ru.yandex.clickhouse.ClickHouseStatementImpl.checkForErrorAndThrow(ClickHouseStatementImpl.java:1094) ~[flink-connector-clickhouse_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.streaming.connectors.clickhouse.shaded.ru.yandex.clickhouse.ClickHouseStatementImpl.sendStream(ClickHouseStatementImpl.java:1061) ~[flink-connector-clickhouse_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.streaming.connectors.clickhouse.shaded.ru.yandex.clickhouse.ClickHouseStatementImpl.sendStream(ClickHouseStatementImpl.java:1026) ~[flink-connector-clickhouse_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.streaming.connectors.clickhouse.shaded.ru.yandex.clickhouse.ClickHouseStatementImpl.sendStream(ClickHouseStatementImpl.java:1019) ~[flink-connector-clickhouse_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.streaming.connectors.clickhouse.shaded.ru.yandex.clickhouse.ClickHousePreparedStatementImpl.executeBatch(ClickHousePreparedStatementImpl.java:381) ~[flink-connector-clickhouse_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.streaming.connectors.clickhouse.shaded.ru.yandex.clickhouse.ClickHousePreparedStatementImpl.executeBatch(ClickHousePreparedStatementImpl.java:364) ~[flink-connector-clickhouse_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.connector.jdbc.internal.executor.SimpleBatchStatementExecutor.executeBatch(SimpleBatchStatementExecutor.java:71) ~[flink-connector-jdbc_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat.attemptFlush(JdbcBatchingOutputFormat.java:207) ~[flink-connector-jdbc_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat.flush(JdbcBatchingOutputFormat.java:174) ~[flink-connector-jdbc_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat.lambda$open$0(JdbcBatchingOutputFormat.java:123) ~[flink-connector-jdbc_2.11-1.12.0-700.jar:1.12.0-700]</span><br><span class="line">    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_77]</span><br><span class="line">    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_77]</span><br><span class="line">    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_77]</span><br><span class="line">    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_77]</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_77]</span><br><span class="line">    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_77]</span><br><span class="line">    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_77]</span><br></pre></td></tr></table></figure>
<p>Flink任务写入CK时, 出现以上异常, 并开始重试, 如果重试次数过多, 就会触发flink的重启, flink重启达到5次, 用户就会收到告警.</p>
<p>目前Flink重试的时候, 会造成Checkpoint期间的数据, 全部重新写入, 即能够保障AT_LEAST_ONCE语义.</p>
<h1 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h1><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220304152821844.png" alt="image-20220304152821844"></p>
<p>在数据每次写入的时候, 都会调用该方法, 判断数据写入频率是否过快了, 如果太快了, 就会执行delay操作.</p>
<p>如何判断过快呢? 通过以下判断</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parts_count_in_partition &gt;= settings-&gt;parts_to_throw_insert</span><br></pre></td></tr></table></figure>
<p>parts_count_in_partition表示所有partition中DataPart个数最多的一个, parts_to_throw_insert是一个配置项, 默认是300</p>
<p>CK每次写入一批数据, 就会生成一个DataPart, 然后会有Merge线程merge多个DP合并为一个.</p>
<p>当<strong>写入太过频繁</strong>或者<strong>Merge过慢</strong>, 就会出现Too Many Parts的问题.</p>
<h2 id="写入频繁"><a href="#写入频繁" class="headerlink" title="写入频繁"></a>写入频繁</h2><p>写入频繁分两种情况:</p>
<p><strong>第一种</strong>, 用户数据量不大, 但flink的参数写入不当, 由于现在Flink多是采用jdbc的接口, 攒批的参数需要用户手动设置, 默认值不随我们配置, 因此会导致批过小的问题</p>
<p><strong>第二种</strong>, 用户数据量较大, flink参数已经被值班人员调整过, 但由于数据量巨大, 依然出现写入过快的问题. 这种问题比较容易出现在”小宽表”上, 即每行数据量比较少, 但是行数特别多的场景.</p>
<h2 id="Merge过慢"><a href="#Merge过慢" class="headerlink" title="Merge过慢"></a>Merge过慢</h2><p>Clickhouse一个节点的Merge线程为48个, 而且由于集群区分读写节点, 写节点就一个, 因此实际上单个shard内, 合并是单点的.</p>
<p>因此解决merge过慢的问题, 可以从<strong>增加写节点个数</strong>方式出发.</p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>针对以上的问题, 我们可以对问题, case by case制定改进方案</p>
<h2 id="MemoryTable方式"><a href="#MemoryTable方式" class="headerlink" title="MemoryTable方式"></a>MemoryTable方式</h2><p>这个方案是针对写入频繁中的第一种情况, 这种情况下, 在CK内部完成攒批, 可以解决用户Flink配置问题</p>
<p>MemoryTable可以参考CK中的Buffer引擎来实现, 但逻辑需要内嵌于MergeTree引擎中, 否则上线成本会增加很多.</p>
<p>但Buffer引擎和MemoryTable还是有一些区别</p>
<ol>
<li>Buffer并不保证数据的一致性, 而在MemoryTable中, 需要实现WAL方式, 支持数据恢复</li>
<li>Buffer引擎是单机的, 而MergeTree需要考虑分布式的能力, 防止节点异常的情况, 需要实现WAL文件的复制能力</li>
</ol>
<p>除去以上的问题, 还有两个细节问题, 在实现上要非常注意:</p>
<p>第一, 如果用户的SQL中有final等特别的关键字, 那么需要跟内存的数据做merge</p>
<p>第二, 如果用户准备修改表结构, 那么内存中的结构也会跟着磁盘的结构一起修改, 此时还需要注意新写入的数据情况</p>
<h3 id="难点一"><a href="#难点一" class="headerlink" title="难点一"></a>难点一</h3><p>final等关键字</p>
<h3 id="难点二"><a href="#难点二" class="headerlink" title="难点二"></a>难点二</h3><p>alter时, 数据写入</p>
<h2 id="列式格式写入"><a href="#列式格式写入" class="headerlink" title="列式格式写入"></a>列式格式写入</h2><p>这种情况可以解决写入频繁中的第二种情况, 如果列存数据的压缩能力, 将批次变大.</p>
<p>由于列存格式的适配, 需要引入新的Flink Connect, 那么在修改过程中, 我们可以在新的Connector中, 实现对于写入频繁的第一种场景的参数进行有效的空,</p>
<p>目前已经支持Parquet格式的写入, 但是Parquet不支持复杂类型, 例如Array/Map等, 最好能够引进ORC或者CK本身的Native的Block数据结构, 减去转换的开销.</p>
<h3 id="难点三"><a href="#难点三" class="headerlink" title="难点三"></a>难点三</h3><p>Native格式是CK最有效的写入格式, CK主要将数据按照自己读起来就行, 省却了压缩编码的工作, 会极大的增加导入的性能.</p>
<p>但Native格式是CK的内部的格式, 可能需要实现在Java中用JNI接口调用C++源码.</p>
<p>该方案在其他列存格式有问题的情况下, 再来实现吧.</p>
<h2 id="读写交替"><a href="#读写交替" class="headerlink" title="读写交替"></a>读写交替</h2><p>下面的三个方面的目标, 都是增加写节点.</p>
<p>目前集群由读写节点确定, 读写节点是固定, 只有故障的时候, 才会变化, 从监控上看, 读写节点压力非常不一致, 写节点的网络写入只有读的一半左右. </p>
<p>因此, 在公共集群上, 可以实现读写能力的交替, 即对同一张表来说, 数据永远只写一个节点(通过表的hash计算), 但对于不同表的写入, 可以是不同的节点, 因此称为读写交替.</p>
<h2 id="多写集群"><a href="#多写集群" class="headerlink" title="多写集群"></a>多写集群</h2><p>比上面的方案更好的, 是完成表级别的多写能力, CK原生也是支持的. 但这种情况下, 在变更时候的数据一致性, 还是需要重点测试的.</p>
<h3 id="难点四"><a href="#难点四" class="headerlink" title="难点四"></a>难点四</h3><p>表多写的影响, Clickhouse原生支持Multi Write, 但不确定是否在复杂环境下, 有异常场景, 可能需要做一次严格的测试来论证这个问题.</p>
<h2 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h2><p>最后一种方案, 是最简单的. 就是shard扩容, 但我们目前一直都没有一个扩shard的方案, 因此该方案, 依赖辉哥的读写分离的方案, 等读写分离实现后, 实现集群扩容会简化很多.</p>
<h3 id="难点五"><a href="#难点五" class="headerlink" title="难点五"></a>难点五</h3><p>读写分离方案, 支持扩容shard实现写入加数</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/28/RemoteShuffleService-RSS%E5%AE%9E%E7%8E%B0%E6%83%85%E5%86%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/02/28/RemoteShuffleService-RSS%E5%AE%9E%E7%8E%B0%E6%83%85%E5%86%B5/" class="post-title-link" itemprop="url">[RemoteShuffleService]: RSS实现情况</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 17:24:22" itemprop="dateCreated datePublished" datetime="2022-02-28T17:24:22+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p>该文档写于2021年4月, 当时按照设计文档实现了RSS的原型(基于Uber的开源RSS), 但是后续应该人事调整, 我开始从事OLAP工作后,就不在开发RSS了.</p>
</blockquote>
<h2 id="Spark-Shuffle任务的现状阐述"><a href="#Spark-Shuffle任务的现状阐述" class="headerlink" title="Spark Shuffle任务的现状阐述"></a>Spark Shuffle任务的现状阐述</h2><p>目前公司内部有最大集群规模已经达到8000多台机器, 总共有近45万核, 1.23PB的内存, 其中每天有10万+个Spark的离线任务在运行.</p>
<p>目前团队正在将HiveSQL的任务都迁移到Spark引擎之上, 提升整体性能和资源利用率, Spark将承接越来越多的业务压力. </p>
<p>但随着Spark应用越来越多, 任务的稳定性受到了越来越多的挑战, 尤其是Spark Shuffle这块的问题, 一旦数据量超过一定阈值, 就会出现大量的Shuffle Fetch失败的情况, 由于Spark做了很好的重试机制, 因此有时候依然能跑出来结果, 但大量计算资源浪费在重试步骤之中; 而有时候因为失败太多, 导致整个App失败退出.</p>
<p>举个真实的案例, 下图是某业务运行的一个UI监控图, 从图中可以看到, 在Failed Stages里面出现了大量的<code>FetchFailedException</code>, 整个程序在不停的Stage重试, 而最后这个case由于失败过多整个APP失败了<br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172502068.png" alt="image-20220228172502068"></p>
<blockquote>
<p>在上图中的19个Failed Stages都是由于<code>FetchFailedException</code>造成的</p>
</blockquote>
<h2 id="Spark-Shuffle任务的瓶颈分析"><a href="#Spark-Shuffle任务的瓶颈分析" class="headerlink" title="Spark Shuffle任务的瓶颈分析"></a>Spark Shuffle任务的瓶颈分析</h2><h3 id="监控发现"><a href="#监控发现" class="headerlink" title="监控发现"></a>监控发现</h3><p>在分析这类问题的时候, 我们发现了经典的”三高”现象, 即网络,磁盘, CPU都很高.</p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172518083.png" alt="image-20220228172518083"><br>如上图所示, 一般出现<code>FetchFailedException</code>时, 此时机器上的监控一般会出现这三者的峰值.<br>磁盘和网络的峰值一般一起出现, 因为Shuffle时会有大量的数据交换<br>CPU出现峰值时有两种情况, 一种<code>Wait</code>比较高(图中黄色部分), 说明CPU忙于处理IO操作,一种<code>Wait</code>不高, 但总体CPU比较高, 这种情况往往是该节点有其他任务运行导致的, <strong>进程之间没做到CPU隔离</strong> 或者一些<strong>热点计算问题</strong>.</p>
<h3 id="Shuffle原理"><a href="#Shuffle原理" class="headerlink" title="Shuffle原理"></a>Shuffle原理</h3><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172616029.png" alt="image-20220228172616029"><br>从监控看到了, Shuffle过程是个”三高”过程, 同时是IO和CPU密集型的过程, 这一节从Shuffle的原理上, 解释一下为什么Shuffle过程为什么会出现瓶颈.</p>
<p>Shuffle本质是一种数据交换机制, 在MR模型中数据是按照(key, value)的元组方式组织的, 经过MapTask之后, Key的数值已经变化了, Shuffle的目标将这些数据重新组合, 相同新Key的数据放到一起处理.</p>
<p>因此, 如果所示, MapTask按照新Key产生了3个不同的数据块, 每个数据块与Reduce的个数对应, ReduceTask则直接去获取对应的数据块(图中用颜色表示)</p>
<p>在Spark的实现之中, MapTask将这些数据重排序后, 写入到同一个文件之中, 通过元数据标识数据所在offset和length. 例如在文件的(offset=0, length=512)的数据为P0, (offset=512, length=1024)的数据为P1. Map阶段要写完所有数据, <strong>磁盘吞吐非常大</strong>.</p>
<p>ReduceTask拿数据的时候, 要获取所有MapTask的输出, 所以必须跟所有MapTask文件所在Server产生网络连接, <strong>网络连接会非常多</strong>. 需要传输所有的MapTask输出到其他节点, 那么<strong>网络吞吐也会非常大</strong>. 其次, 我们拿P1数据的时候, 是直接读取文件的中间位置的, 因此<strong>随机IO会非常多, 磁盘繁忙</strong>. 最后为了减少网络和磁盘的压力, Spark加入了<strong>Shuffle过程的Merge和Shuffle数据压缩能力</strong>, 这就加重CPU的压力, 但一般情况下CPU压力没那么大, 除非<strong>被别的任务影响</strong></p>
<p>如果有兴趣了解更加详细的Shuffle原理的同学, 可以参考<a href="http://lionheartwang.github.io/blog/2018/03/11/spark-shuffle-implementation/">这篇文章</a></p>
<h3 id="原因归纳"><a href="#原因归纳" class="headerlink" title="原因归纳"></a>原因归纳</h3><p>综上所述, 我们简单归纳原因:</p>
<ul>
<li>大量网络连接, 且非常多的网络小包</li>
<li>磁盘大吞吐, 且随机读取, 触发IO瓶颈</li>
<li>计算存储耦合, CPU密集型任务影响Shuffle</li>
</ul>
<h3 id="目前的解决方式"><a href="#目前的解决方式" class="headerlink" title="目前的解决方式"></a>目前的解决方式</h3><p>针对以上的原因, 目前团队也有一些处理措施:</p>
<ul>
<li>增加超时配置项, 缓解网络问题</li>
<li>增加Yarn Shuffle Service处理IO的线程个数,缓解IO问题</li>
<li>隔离集群, 给队列打上独立NodeLable, 去除其他进程影响</li>
</ul>
<p>以上措施在一定程度上缓解了<code>FetchFailedException</code>问题, 但这些措施都治标不治本:</p>
<ul>
<li>增加网络超时, 会加大重试的时间, 导致异常情况下时间更长</li>
<li>Yarn节点的IO已经达到硬件上线, 无法再通过多线程加速</li>
<li>隔离集群, 使得集群资源的使用率低, 平均CPU使用率在30%以下 </li>
</ul>
<p>但随着业务数据量越来越多, 该问题又开始出现了, 是时候提出一种根治的方案了</p>
<h2 id="Spark-Shuffle任务的改进方案"><a href="#Spark-Shuffle任务的改进方案" class="headerlink" title="Spark Shuffle任务的改进方案"></a>Spark Shuffle任务的改进方案</h2><h3 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h3><p>这个章节, 主要针对上文提到的”三高”问题, 看看从设计上如何解决这些问题</p>
<h4 id="网络问题"><a href="#网络问题" class="headerlink" title="网络问题"></a>网络问题</h4><p>在原有的网络模型之中, 网络连接个数为M*R, 而M和R都在Executor之中, 可以复用网络连接, 实际的连接为E^2. 如果executor个数为2000个, 那么会有4百万的连接, 一些排在后面网络连接经常出现超时.</p>
<blockquote>
<p>为了性能, Spark在Reduce启动的时候, 会尽可能的建立所有的链接</p>
</blockquote>
<p>另外一个问题是网络传输的时候小包太多了, 一个分区的平均大小&lt;1MB, 大量的时间消耗在网络连接的创建过程之中, 能不能提前聚合数据, Reduce启动的时候, 直接读取数据就行了.</p>
<p>对于这两个问题, <strong>Push-Shuffle</strong>可以很好的解决这两个问题<br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172633521.png" alt="image-20220228172633521"></p>
<p>该方案数据的流程, 并不是由ReduceTask主动Pull, 而是由MapTask主动Push到ShuffleService里.<br>如图所示, 2个MapTask计算完分区数据P0后, 将两者的P0都push到第一个Shuffle Service.<br>ReduceTask启动后, 直接获取第一个Shuffle Service之中P0数据即可.</p>
<p>回看原来的问题, 该方案的连接个数为(E*S + E), S为RSS的个数, 一般在10-50之间, 远远小于E的个数, 有效减少连接;ShuffleService会合并数据(只要读取的时候, 多读几个块就好), 可以方便的处理小包问题.</p>
<blockquote>
<p>发送时的小包, 可以通过同步发送P0和P1到同一个节点来解决</p>
</blockquote>
<p>此外<strong>Push-Shuffle</strong>将随机IO变成了顺序IO, 解决了随机IO问题.</p>
<h4 id="磁盘问题"><a href="#磁盘问题" class="headerlink" title="磁盘问题"></a>磁盘问题</h4><p>磁盘问题一个在于随机读写, <strong>Push-Shuffle</strong>将Reduce阶段的随机读写变成顺序读写<br>另外一个问题就是读写速度, 我们的解决思路就是使用<strong>SSD替换HDD</strong>, 同时SSD对于随机读写也非常友好, 因此硬件加速完全好于预期.<br>那么用Spark原来的External Shuffle Service是否也能上SSD解决这个问题呢?<br>答案是否定的, 原因在于ESS是和Yarn强制绑定的, 代码逻辑在NodeManager的进程之中, 替换全部Yarn集群的磁盘, 成本上根本无法接受. 因此RSS必须是<strong>存储计算分离</strong>的, 也就是需要是个完全<strong>独立服务</strong>.<br>总结来说, 解决磁盘问题方法是: <strong>Push-Shuffle</strong>, <strong>SSD加速</strong> 和 <strong>独立服务</strong></p>
<h4 id="CPU问题"><a href="#CPU问题" class="headerlink" title="CPU问题"></a>CPU问题</h4><p>如&lt;瓶颈分析&gt;中提到的, CPU问题并不是Shuffle的核心问题, 主要问题在于热点和隔离.<br>为了解决热点问题, 我们引入了<strong>Shuffle 调度器</strong>, 通过监控App里面磁盘网络内存压力, 防止出现单服务器热点, 拖慢计算或者导致失败.<br>对于隔离问题, 我们采用<strong>独立部署</strong>, 解除对Yarn集群的依赖</p>
<h3 id="Remote-Shuffle-Service方案"><a href="#Remote-Shuffle-Service方案" class="headerlink" title="Remote Shuffle Service方案"></a>Remote Shuffle Service方案</h3><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172650782.png" alt="image-20220228172650782"><br>由上文的铺垫, 整体架构也呼之欲出了, 整体采用典型的Master-Slave模式, 其中Client为Spark App, Master为Remote Shuffle Service Manager(RssManager), Slave为Remote Shuffle Service Server(RssServer), 还有DFS作为数据备份, Zookeeper作为元数据存储.</p>
<h4 id="Remote-Shuffle-Service-Manager"><a href="#Remote-Shuffle-Service-Manager" class="headerlink" title="Remote Shuffle Service Manager"></a>Remote Shuffle Service Manager</h4><p>作为整个集群的控制节点, 负责整个集群与客户端的任务调度, 元数据管理等主要工作. </p>
<ul>
<li>Manager会采用主备方式完成服务高可用, 主备实例会通过Zookeeper进行选主工作</li>
<li>Manager会采取无状态应用模式, 整体状态都会同步到Zookeeper之中, Slave可以在重启时重建全部的状态</li>
<li>为了加速备实例的启动速度, 主备实例会保持心跳, 并定时同步全量或增量状态给备节点</li>
<li>Manager与Server会保持心跳状态, Server通过心跳上报资源容量信息. </li>
<li>Manager会主动想Server下发RPC通信</li>
<li>客户端会与Manager建立连接发送RPC请求, 但是Manager不会主动给客户端发送RPC请求</li>
<li>Manager与资源调取器(Yarn/K8s)保持连接, 查询任务状态, 用以退出清理</li>
<li>Manager内部设有调度器组件, 可以插件式的设置调度策略</li>
<li>Manager内部有元数据管理, 主要是App级别的信息, Task级别的信息由Driver持有, 通过RPC请求送达Manager</li>
<li>Manager服务有WebUI接口, 统计App级别监控信息</li>
<li>Manager服务有jmx接口, 指标方便指标统计</li>
</ul>
<h4 id="Remote-Shuffle-Service-Server"><a href="#Remote-Shuffle-Service-Server" class="headerlink" title="Remote Shuffle Service Server"></a>Remote Shuffle Service Server</h4><p>作为整个集群的数据节点, 负责与客户端Spark App进行数据交互</p>
<ul>
<li>Server是数据节点, 只会跟客户端进行数据通讯, 不参与控制通信</li>
<li>Server与Manager会保持心跳, 同时会与Manager有控制流的RPC请求</li>
<li>Server会将数据首先写入到本地的SSD, 如果开启了备份的话, 也会以pipeline的方式, 同步给其他备份节点, 最后开启了慢写入的话, 才会备份给DFS. 由于DFS一般有HDD磁盘组成, 因此性能会受到巨大的影响</li>
<li>默认情况下, 一个Reduce任务会开一个文件句柄, 用于写入Map的数据, 同时还有一个index文件记录数据块位置与TaskId的对应关系</li>
<li>读取数据时候, 会根据TaskId过滤无效的数据块</li>
</ul>
<h4 id="Spark-App"><a href="#Spark-App" class="headerlink" title="Spark App"></a>Spark App</h4><p>作为整个集群的客户端, 负责实现Spark对外的接口, 并与RSS交互, 该模块除了实现SparkShuffleManager的接口之外, 还要实现Spark App的事件处理, 还需要在调度上处理任务失败的情况</p>
<ul>
<li>Shuffle接口: 实现Shuffle注册, 数据读取, 数据写入等工作</li>
<li>Event接口: 实现整体控制流的处理, 例如App启停, Stage启停</li>
<li>Schedule接口: 当任务失败时的, 需要重试, push Shuffle的重试方式不同, 目前Spark并没有有接口暴露, 可能会侵入式的修改源码</li>
</ul>
<h4 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h4><p>作为整个集群的元数据中心, ZK承担着元数据备份, 服务发现, 主备切换等功能</p>
<ul>
<li>Manager会将App信息写入到ZK, 方便备实例恢复</li>
<li>Manager通过ZK进行主备切换和监控</li>
<li>Client会通过ZK的地址获取到Manager的地址</li>
</ul>
<h4 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h4><p>作为整个集群的数据备份中心, 目前公司内部只有HDFS作为DFS实现, 但是性能堪忧.<br>但当RSS集群也是以HDD磁盘为主时, Reduce任务直接获取DFS上的数据, 是个好的选择.<br>另外DFS方式的稳定性会更加好</p>
<h3 id="方案效果"><a href="#方案效果" class="headerlink" title="方案效果"></a>方案效果</h3><p>我们选了两个典型的案例: </p>
<h4 id="业务1"><a href="#业务1" class="headerlink" title="业务1"></a>业务1</h4><p>使用默认的Shuffle方式, 总耗时7.3h, 有23个<code>Failed Stage</code>,错误类型全是<code>FetchFailed</code><br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172706050.png" alt="image-20220228172706050"></p>
<p>使用RemoteShuffleService模式, 总耗时2.9小时, 无任何失败的Stage, 总Shuffle Write数据量在15TB左右, 最大ShuffleStage为5.6TB<br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172721493.png" alt="image-20220228172721493"></p>
<h3 id="业务2"><a href="#业务2" class="headerlink" title="业务2"></a>业务2</h3><p>使用默认的Shuffle方式, 总耗时1.6h, 有21个<code>Failed Stage</code></p>
<p>使用RemoteShuffleService模式, 总耗时38分钟, 无任何失败的Stage, Shuffle Write数据量在8TB左右, 最大ShuffleStage为0.3TB</p>
<h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><div class="table-container">
<table>
<thead>
<tr>
<th>业务</th>
<th>地图</th>
<th>服务分</th>
</tr>
</thead>
<tbody>
<tr>
<td>总Shuffle量</td>
<td>15TB</td>
<td>8TB</td>
</tr>
<tr>
<td>最大ShuffleStage</td>
<td>5.6TB</td>
<td>0.3TB</td>
</tr>
<tr>
<td>默认Shuffle耗时</td>
<td>7.3小时</td>
<td>1.6小时</td>
</tr>
<tr>
<td>默认Shuffle失败Stage个数</td>
<td>23个</td>
<td>21个</td>
</tr>
<tr>
<td>RSS耗时</td>
<td>2.9小时</td>
<td>0.75小时</td>
</tr>
</tbody>
</table>
</div>
<h2 id="Spark-Shuffle任务的未来展望"><a href="#Spark-Shuffle任务的未来展望" class="headerlink" title="Spark Shuffle任务的未来展望"></a>Spark Shuffle任务的未来展望</h2><p>目前RSS属于刚起步阶段, 一期上线时(21年Q2)只会覆盖部分业务场景, 未来还需要在以下方向做深度的优化:</p>
<ol>
<li>持续优化性能和功能, 减少小文件传输的等问题</li>
<li>完善服务的可运维性, 增加运维的页面, 提供各种监控指标</li>
<li>提高服务的鲁棒性, 能够处理各种服务异常, 在绝大多数场景下能够正常完成计算</li>
<li>提高服务可测试性, 完备各种测试用例, 防止异常bug对数据正确性的影响</li>
<li>智能决策Shuffle类型, Spark引擎能够自动决策Shuffle类型, 一旦RSS失败后能够回退到默认的Shuffle</li>
<li>优化Shuffle数据的调度策略, 解决Shuffle热点瓶颈问题, 优化集群整体使用率</li>
<li>Cloud Native支持, 提供较好的弹性伸缩能力, 提高集群利用率</li>
<li>支持与大数据其他组件混部, 提高集群利用率</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/28/RemoteShuffleService-RSS%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/02/28/RemoteShuffleService-RSS%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/" class="post-title-link" itemprop="url">[RemoteShuffleService]: RSS设计文档 </a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 17:19:01" itemprop="dateCreated datePublished" datetime="2022-02-28T17:19:01+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>9 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Shuffle-Service设计文档"><a href="#Shuffle-Service设计文档" class="headerlink" title="Shuffle Service设计文档"></a>Shuffle Service设计文档</h1><blockquote>
<p>该文档写于2021年1月</p>
</blockquote>
<h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><h3 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a>业务场景</h3><p>目前公司内部有3个集群, 最大集群规模已经达到8000多台机器, 总共有近45万核, 1.23PB的内存.<br>待补完…</p>
<h3 id="Spark业务负载"><a href="#Spark业务负载" class="headerlink" title="Spark业务负载"></a>Spark业务负载</h3><p>目前集群上, 每天有60万个离线任务在运行, 其中Spark任务有10万个. 公司未来整体战略会将所有HiveMR的任务替换Spark任务, 今年将整个数据平台上的SQL任务基本上都迁移到Spark上.<br>整体的资源利用率得到了巨大的提升, 但随着Spark应用越来越多, 任务的稳定性受到了越来越多的挑战, 尤其是Spark Shuffle这块的问题, 总是让运维人员头疼不已, 一旦当天数据量超过历史, 会导致任务失败, 就需要隔离机器重新运行, 等业务量降低时候, 再释放空闲资源, 给整个团队巨大的运维成本.</p>
<h3 id="当前面临的问题"><a href="#当前面临的问题" class="headerlink" title="当前面临的问题"></a>当前面临的问题</h3><p>我们分析Spark Shuffle的问题, 发现目前Shuffle机制存在如下几个问题:</p>
<ol>
<li>计算存储不分离, Spark计算和Shuffle的IO操作混在一起, 极易因为CPU过高导致Shuffle超时失败</li>
<li>机器超卖, 虽然提高了整体使用率, 但是会因为调度不均匀, 导致失败CPU飙升</li>
<li>Yarn Shuffle Service内嵌于NodeManager之中, 无法给全部集群替换SSD加速IO效率</li>
<li>Pull模式的Shuffle, Reduce阶段有大量的随机读取过程, 导致磁盘IO飙升</li>
<li>Reduce阶段数据未提前聚会, 导致导致大量网络小包产生, 造成网络IO飙升</li>
<li>调度器无法识别CPU/IO繁忙状态, 导致任务依然下发到近乎满载的机器</li>
</ol>
<h3 id="业界的解决方式"><a href="#业界的解决方式" class="headerlink" title="业界的解决方式"></a>业界的解决方式</h3><p>随着Spark成为业界的批处理的标准, 在各大互联网公司之中, Spark Shuffle以上的问题都慢慢出现, 无法通过简单的调优解决这个问题也慢慢成为这个大家的共识. 因此各个公司都推出了自己的解决方案:</p>
<ol>
<li>Spark社区和LinkedIn: 领英在VLDB2020发了一篇Paper, 提出<code>Push based Shuffle</code>来解决4和5点, 该方案依然嵌入在原有的Spark框架之中, 因此该方案最容易被社区接受, 现在也慢慢的在合入代码</li>
<li>Uber: 在今年的Spark Meetup里提出了他们的独立的Shuffle Service的解决方案, 也是目前唯一开源的独立Shuffle Service服务, 意图解决1-5点问题, 并引入SSD解决IO问题. 但目前开源出来的代码健壮性不强, Task重试的时候, 数据会出现冗余,还需要很长的优化之路</li>
<li>Facebook: 也有名为cosico的独立Shuffle Service, 从架构图上看他们解决了4-6的问题, 但容错使用了DFS系统, Reduce数据也是从DFS直接获取的, 因此性能是打问号的, 且未公开源码, 并不确定具体如何实现</li>
<li>阿里云: 20年12月份, 阿里云EMR团队公布了他们的Shuffle Service的方案, 同样未开源, 从公开文章上看, 他们除了解决Shuffle稳定性问题(1-5点), 更重要的点是为了解决Spark on k8s在磁盘上性能解决方案. 同样阿里云的方案也未开源</li>
<li>Intel: 作为一家硬件厂商, 推出了自己的Shuffle Service, 目的是为来卖RDMA产品, 暂时应该不会去采购硬件, 因此略过</li>
</ol>
<h3 id="设计目标及范围"><a href="#设计目标及范围" class="headerlink" title="设计目标及范围"></a>设计目标及范围</h3><p>简单调研几家产品之后, 我们打算博采众长, 并找到符合自己的场景的方案, 主要参考Uber和阿里云:</p>
<ul>
<li>独立的Shuffle服务, 存储计算分离(解决1-2)</li>
<li>SSD存储, 加速IO效率, 减少计算资源, 提高整体资源利用率(解决3)</li>
<li>Push based Shuffle, Server端聚合后再Reduce(解决4-5)</li>
</ul>
<p>相对于阿里云, 我们不需要做的:</p>
<ul>
<li>不需要全部替换原有Shuffle Service, 能用Adaptive的方式, 决策使用哪种Shuffle模式</li>
<li>最好是CloudNative的方案, 但是不强制</li>
</ul>
<p>而相对于他们两个的方案, 我需要:</p>
<ul>
<li>IO敏感型调度, 解决热点问题</li>
</ul>
<h2 id="Shuffle-Service顶层设计"><a href="#Shuffle-Service顶层设计" class="headerlink" title="Shuffle Service顶层设计"></a>Shuffle Service顶层设计</h2><h3 id="服务架构图"><a href="#服务架构图" class="headerlink" title="服务架构图"></a>服务架构图</h3><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172007077.png" alt="image-20220228172007077"></p>
<p>整体架构会采用典型的Master-Slave模式, 其中Client为Spark App, master为Remote Shuffle Service Manager(RssManager), Slave为Remote Shuffle Service Server(RssServer), 还有DFS作为数据备份, Zookeeper作为元数据存储.</p>
<h4 id="Remote-Shuffle-Service-Manager"><a href="#Remote-Shuffle-Service-Manager" class="headerlink" title="Remote Shuffle Service Manager"></a>Remote Shuffle Service Manager</h4><p>作为整个集群的控制节点, 负责整个集群与客户端的任务调度, 元数据管理等主要工作. </p>
<ul>
<li>Manager会采用主备方式完成服务高可用, 主备实例会通过Zookeeper进行选主工作</li>
<li>Manager会采取无状态应用模式, 整体状态都会同步到Zookeeper之中, Slave可以在重启时重建全部的状态</li>
<li>为了加速备实例的启动速度, 主备实例会保持心跳, 并定时同步全量或增量状态给备节点</li>
<li>Manager与Server会保持心跳状态, Server通过心跳上报资源容量信息. </li>
<li>Manager会主动想Server下发RPC通信</li>
<li>客户端会与Manager建立连接发送RPC请求, 但是Manager不会主动给客户端发送RPC请求</li>
<li>Manager与资源调取器(Yarn/K8s)保持连接, 查询任务状态, 用以退出清理</li>
<li>Manager内部设有调度器组件, 可以插件式的设置调度策略</li>
<li>Manager内部有元数据管理, 主要是App级别的信息, Task级别的信息由Driver持有, 通过RPC请求送达Manager</li>
<li>Manager服务有WebUI接口, 统计App级别监控信息</li>
<li>Manager服务有jmx接口, 指标方便指标统计</li>
</ul>
<h4 id="Remote-Shuffle-Service-Server"><a href="#Remote-Shuffle-Service-Server" class="headerlink" title="Remote Shuffle Service Server"></a>Remote Shuffle Service Server</h4><p>作为整个集群的数据节点, 负责与客户端Spark App进行数据交互</p>
<ul>
<li>Server是数据节点, 只会跟客户端进行数据通讯, 不参与控制通信</li>
<li>Server与Manager会保持心跳, 同时会与Manager有控制流的RPC请求</li>
<li>Server会将数据首先写入到本地的SSD, 如果开启了备份的话, 也会以pipeline的方式, 同步给其他备份节点, 最后开启了慢写入的话, 才会备份给DFS. 由于DFS一般有HDD磁盘组成, 因此性能会受到巨大的影响</li>
<li>默认情况下, 一个Reduce任务会开一个文件句柄, 用于写入Map的数据, 同时还有一个index文件记录数据块位置与TaskId的对应关系</li>
<li>读取数据时候, 会根据TaskId过滤无效的数据块</li>
</ul>
<h4 id="Spark-App"><a href="#Spark-App" class="headerlink" title="Spark App"></a>Spark App</h4><p>作为整个集群的客户端, 负责实现Spark对外的接口, 并与RSS交互, 该模块除了实现SparkShuffleManager的接口之外, 还要实现Spark App的事件处理, 还需要在调度上处理任务失败的情况</p>
<ul>
<li>Shuffle接口: 实现Shuffle注册, 数据读取, 数据写入等工作</li>
<li>Event接口: 实现整体控制流的处理, 例如App启停, Stage启停</li>
<li>Schedule接口: 当任务失败时的, 需要重试, push Shuffle的重试方式不同, 目前Spark并没有有接口暴露, 可能会侵入式的修改源码</li>
</ul>
<h4 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h4><p>作为整个集群的元数据中心, ZK承担着元数据备份, 服务发现, 主备切换等功能</p>
<ul>
<li>Manager会将App信息写入到ZK, 方便备实例恢复</li>
<li>Manager通过ZK进行主备切换和监控</li>
<li>Client会通过ZK的地址获取到Manager的地址</li>
</ul>
<h4 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h4><p>作为整个集群的数据备份中心, 目前公司内部只有HDFS作为DFS实现, 但是性能堪忧.<br>但当RSS集群也是以HDD磁盘为主时, Reduce任务直接获取DFS上的数据, 是个好的选择.<br>另外DFS方式的稳定性会更加好</p>
<h3 id="交互图架构图"><a href="#交互图架构图" class="headerlink" title="交互图架构图"></a>交互图架构图</h3><p>下面考虑一下RSS是如何和Spark的各个实例交互的, 先一个Map和Reduce任务是如何进行控制流通信的, 然后再看数据是如何写入的</p>
<h4 id="控制流图"><a href="#控制流图" class="headerlink" title="控制流图"></a>控制流图</h4><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172021282.png" alt="image-20220228172021282"></p>
<ol>
<li>Spark Driver向Manager发送申请Shuffle资源的请求</li>
<li>Manager返回结果, 并指明ReduceTaskId对应的Server地址</li>
<li>Driver根据位置分配Spark任务</li>
<li>SparkTask计算各自的数据, 发送到对应Server</li>
<li>Task写完所有的Map数据之后, Executor向DriverCommit任务</li>
<li>完成所有任务的时候, Driver向Manager发送CommitStage请求, 目的是传递最后成功的TaskId给到ShuffleManager</li>
<li>Manager将TaskId等消息,下发到各个Server</li>
<li>Driver下发Reduce任务(如果也是ShuffleMapTask的话, 依然需要先申请资源)</li>
<li>ReduceTask向对应的Server拉去数据, Server需要根据TaskId过滤重复数据</li>
</ol>
<h4 id="数据流图"><a href="#数据流图" class="headerlink" title="数据流图"></a>数据流图</h4><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172040055.png" alt="image-20220228172040055"></p>
<ul>
<li>MapTask先会将数据完成预聚合, 按照Partition分区</li>
<li>然后两个MapTask都将将P0,P1的数据推送到第一个Server</li>
<li>Server会将两个MapTask的数据都写入到一个文件之中, 因此第一个Server有P0和P1两个文件, 第二个Server有P2,P3,P4三个文件</li>
<li>启动ReduceTask时候, 直接会去对应Server流式拉取数据</li>
</ul>
<h2 id="Remote-Shuffle-Service设计要点"><a href="#Remote-Shuffle-Service设计要点" class="headerlink" title="Remote Shuffle Service设计要点"></a>Remote Shuffle Service设计要点</h2><h3 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h3><p>可靠性从三个方面来阐述, 一个是任务可靠性, 指异常发生的整体重试机制, 这里的重试指流程的重试, 而不是消息的重试, 因为RPC消息大多数可以做到幂等, 做不到幂等的就会出现不一致场景, 就是数据一致性问题. 另外一点数据可靠性, 只Shuffle数据文件的备份问题.</p>
<h4 id="任务可靠性"><a href="#任务可靠性" class="headerlink" title="任务可靠性"></a>任务可靠性</h4><p>首先我们还是回到上面的数据流图, 并标识其中可能失败的场景<br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172054924.png" alt="image-20220228172054924"><br>下面分别解释一下错误的具体含义:</p>
<ol>
<li>MapDataPush失败值, MapTask之中单个Partition数据无法推送到对应的Server, 造成的原因一般为网络问题等</li>
<li>慢节点/坏节点, 当出现这种场景的时候, 是多个MapTask推送到同一个Server时候的出现</li>
<li>MapTask失败, 这个场景为部分Partition数据写入成功, 部分写入失败场景, 造成错误的原因很多, 比如Executor OOM</li>
<li>Map推测执行, 指启动两个Task计算同一份数据, 会导致所有数据写了2份</li>
<li>Reduce拉取失败, 指单次失败, 可能网络问题导致</li>
<li>Reduce持续失败, 拉取多次失败, 可能是慢节点等</li>
<li>Server失败重启, 进程级别的重启, 服务多一会时间会恢复</li>
<li>Server丢失数据, 一般是磁盘问题, 导致数据丢失了</li>
</ol>
<h6 id="PushData失败-多次失败"><a href="#PushData失败-多次失败" class="headerlink" title="PushData失败/多次失败"></a>PushData失败/多次失败</h6><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172110777.png" alt="image-20220228172110777"></p>
<ol>
<li>启动MapTask, Task之中携带Reduce对应Server地址, 一个Reduce对应2个地址, 正常情况只会使用前面一个</li>
<li>MapTask计算Partition任务会将数据写入到临时</li>
<li>向Server写入数据</li>
<li>写入失败,返回错误</li>
<li>从临时文件之中获取Partition数据</li>
<li>重试写入(第一次失败的时候, 依然写入老地址, 第二次失败时, 写入备用地址)</li>
<li>重试, 直到达到达到最大次数</li>
<li>如果重试未成功, 将失败的节点加入黑名单, 然后重新运行整个Stage</li>
<li>如果重试成功, 启动Reduce任务, 此时需要指明备节点是否存有数据.</li>
<li>此时对应整个Reduce可能两个节点都存在数据, 因此需要向两个节点拉取数据</li>
</ol>
<blockquote>
<p>PushData的Block粒度为单个Partition, 如果再小, 那么数据一致性就无法保证了, 这里编程时候需要注意</p>
</blockquote>
<h6 id="关于Block重试的详细说明"><a href="#关于Block重试的详细说明" class="headerlink" title="关于Block重试的详细说明"></a>关于Block重试的详细说明</h6><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172158952.png" alt="image-20220228172158952"></p>
<ol>
<li>网络写失败, 无妨, 重试即可</li>
<li>写本地失败, 写了一些, 需要Stage失败</li>
<li>写commit文件失败, 需要Stage失败</li>
<li>网络返回失败, Server做到幂等</li>
</ol>
<p>2和3的问题, 大致是因为服务节点问题导致的, 这个目前比较难以处理, 先不管了[TODO]<br>如果做到幂等, 需要在元数据信息里面记载对应的taskAttemptId</p>
<h5 id="数据重复"><a href="#数据重复" class="headerlink" title="数据重复"></a>数据重复</h5><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172216824.png" alt="image-20220228172216824"></p>
<ol>
<li>Driver启动Map任务</li>
<li>开始写Partition数据, 成功写入P0</li>
<li>但P1数据还没有完成写入</li>
<li>此时Task任务遇到异常退出</li>
<li>Driver启动Task任务重试</li>
<li>Task又重复写入一遍P0数据</li>
<li>同时也完成P1数据的写入, 此时系统之中有2份P0, 1份P1. 由于写入数据时, 含有Task信息, 因此Server知道2份P0数据, 分别由哪个Task写入</li>
<li>Executor向Driver 确认成功的Task</li>
<li>Driver向Manager发送Map任务也完成了, 并将正常完成任务的TaskId信息发给Manager</li>
<li>Manager直接将这些信息下发到Server</li>
<li>Driver启动Reduce任务</li>
<li>Reduce任务拉取数据的时候, 如果发现数据块对应的TaskId不在commitTask列表之中, 就会自动跳过这个数据块</li>
</ol>
<blockquote>
<p>commitTask下发给RSS的话, 容易造成元数据膨胀问题, 但如果将这些元数据放在Spark里面的话, 就会造成代码耦合程度太大了. 因此先看看编程时候能不能将代码耦合去除, 如果去除的话, 直接在ReduceTask测过滤</p>
<p>推测执行的难点在于, 两个独立进程写入同一个数据块, 那么在Server端就必须加锁来防止竞争, 但是一旦加锁, 性能就会收到影响</p>
</blockquote>
<h5 id="拉取失败"><a href="#拉取失败" class="headerlink" title="拉取失败"></a>拉取失败</h5><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172232885.png" alt="image-20220228172232885"></p>
<ol>
<li>Driver启动Reduce任务</li>
<li>ReduceTask开始拉取数据, 但是返回异常</li>
<li>此时跟MapTask一样, 先开始Partition级别拉取重试, 如果第二次失败的时候, 开始拉取备份节点数据. 为了防止重复, 拉取成功的数据块, 需要记录对应的Task号, 拉取备份节点的时候, 需要重新过滤</li>
<li>如果Partition级别的重试未成功</li>
<li>上报给Driver, 准备重试Task</li>
<li>下发重试任务到新的Executor</li>
<li>此时如果一直失败的话, 有两个选择, 一个是直接宣布App失败了, 另外就是重选上一个Stage, 先选第一种</li>
</ol>
<h5 id="Server失败"><a href="#Server失败" class="headerlink" title="Server失败"></a>Server失败</h5><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172249213.png" alt="image-20220228172249213"></p>
<ol>
<li>以MapTask为例, ReduceTask其实也类似</li>
<li>MapTask开始写入数据</li>
<li>此时对应Server进程shutdown了, 对应Manager来就是心跳消失</li>
<li>MapTask首先会失败, 失败后会再次重试, 一般partition级别重试会一直失败, 那么就会换一个节点写入.</li>
<li>此时如果Shuffle Server能马上重启, 重新接入心跳, 那么Manager就会当没事发送. 如果超过一定时间, 还没有重启, 那么Manager会告之Driver数据丢失(这里可以被动的)</li>
<li>Driver发现DataLost之后, 先查看是否开启数据备份功能, 如果有, 则继续. 如果没有开启数据备份, 那么就开始停止整个Stage, 等待重新下发全部的任务(如果有Reduce任务, 且数据没有开启备份功能, 则直接APP失败退出)</li>
</ol>
<blockquote>
<p>如果Server重启且不能恢复的话, 直接让APP失败, 由上层平台重试也许是个最好的方案</p>
</blockquote>
<p>另外一种方式, Service一旦失败, 重试这个Stage, 上一个Stage的数据必须在DFS中有备份, 这样才能重试Stage.</p>
<h4 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h4><p>数据的一致性问题, 其实在上面已经单独说过了, 但这里还是要单独拿出来看的, 因为数据不一致, 结果一般就不对了.<br>不一致情况的原有有以下几种:</p>
<ul>
<li>MapTask重试, 一些数据写了两遍</li>
<li>推测执行数据有两份</li>
<li>Server失败, 导致一份数据写到两个Server, 这时有些数据重复了, 有些数据没重复<br>解决上面的问题的思路, 就是读的时候, 需要过滤多余的数据.<br>对于同一个Server写了2遍, 这时通过CommittedTaskId过滤掉多余Task产生的数据<br>对于多个Server数据, 读取的时候, 要记录哪些Task任务已经被消费了, 如果被消费了就不需要重新读取了</li>
</ul>
<h4 id="数据可靠性"><a href="#数据可靠性" class="headerlink" title="数据可靠性"></a>数据可靠性</h4><p>数据备份功能, 一般有几个问题要选择: 谁来备份, 怎么备份, 备份到哪儿</p>
<h5 id="谁来备份"><a href="#谁来备份" class="headerlink" title="谁来备份"></a>谁来备份</h5><p>一般有客户端和服务端备份, 客户端备份,就是客户端直接写多份数据, 服务端备份的话, 客户端只写一份数据, 然后服务端自己写到备份地方去<br>客户端备份的优点是简单, 缺点点网络连接多些, 并且与后端耦合<br>服务端是反过来的<br>我们这儿选服务端备份, 因为备份到哪儿还不是很确定</p>
<h5 id="怎么备份"><a href="#怎么备份" class="headerlink" title="怎么备份"></a>怎么备份</h5><p>这儿有同步和异步的选项, 因为是临时数据, 所以Shuffle的备份最多应该就2个, 不会有半异步的选项<br>同步的特点是, 速度慢, 但是能保证数据一致<br>异步的话, 性能会好, 但是容易导致数据并没有完全ready<br>我们这儿选同步, 因为如果是异步的话, 上面的任务可靠性的处理会更加复杂一些, 这个性能等后续再优化吧</p>
<h5 id="备份到哪儿"><a href="#备份到哪儿" class="headerlink" title="备份到哪儿"></a>备份到哪儿</h5><p>在我们的系统里面有两个选项, 其他Server或者DFS.<br>如果放到其他实例里面的话, 因为机器也是SSD的, 所以性能会好一些, 但是DFS性能会比较差, 不过稳定性会比较好, 不需要考虑数据丢失的问题了<br>这里优先DFS, 因为DFS有人维护.</p>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><h4 id="主备切换"><a href="#主备切换" class="headerlink" title="主备切换"></a>主备切换</h4><p>主备切换的能力依靠ZK来完成:</p>
<ul>
<li>客户端和Server会监控ZK的地址, 如果Manager地址变化之后, 会主动切换地址和端口</li>
<li>主Manager会在ZK上写入数据, 而备Manager会一直监控着, 如果发现节点丢失, 即主Manager失联, 备Manager会读取Zookeeper上的元数据, 然后变成主Manager写入数据.</li>
</ul>
<h4 id="主备切换-任务不中断"><a href="#主备切换-任务不中断" class="headerlink" title="主备切换, 任务不中断"></a>主备切换, 任务不中断</h4><p>做到任务不中断, 需要有以下条件</p>
<ul>
<li>切换时间短</li>
<li>无任何不一致状态, 或者状态都可以恢复</li>
<li>连接重试<br>要做到切换时间短, 需要备节点时刻监控主节点的状态, 不能落后太多, 不然就会启动延迟<br>尽量将必要的元数据信息都写入到ZK之中, 但ZK并非更新友好型存储系统, 因此也需要实现中间状态重构的能力,而这个重构不能出现状态丢失<br>客户端的所有RPC请求, 都要有重试功能, 一旦发现主备切换, RPC失败之后, 迅速切换到另外的节点.</li>
</ul>
<h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><h4 id="页面"><a href="#页面" class="headerlink" title="页面"></a>页面</h4><p>参考Livy的实现, 只实现到APP级别即可<br>APP: Id, 提交时间, 结束时间, 时长, 当前Shuffle文件个数, 当前shuffle存储总量</p>
<h4 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h4><p>App总量: 个数, shuffle存储量, 文件总个数<br>资源容量: 磁盘,内存slot, cpu<br>JVM相关: 内存, 线程</p>
<h4 id="慢节点告警"><a href="#慢节点告警" class="headerlink" title="慢节点告警"></a>慢节点告警</h4><p>如何定义慢节点?</p>
<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><h4 id="兼容性方案"><a href="#兼容性方案" class="headerlink" title="兼容性方案"></a>兼容性方案</h4><p>兼容性包含客户端和服务端之间,以及服务端Manager和Server时间.<br>客户端目前只会支持Spark2.4.3版本以及Spark3.0版本.服务端需要同时支持这两个版本的接入, 因此整体差异只会在于Spark与Client接口层次, RssServer的Client和Server之间的通信兼容性必然要遵循. 可以适当的在控制流监控预留部分json字段来保持未来的兼容.<br>服务端的Manager和Server的RPC也同上诉方式.<br>如果后续改动实在无法, 通过灰度升级的方案处理</p>
<h4 id="多版本支持"><a href="#多版本支持" class="headerlink" title="多版本支持"></a>多版本支持</h4><p>由于兼容性和容错的考虑, Push方式的Shuffle Service很难实现滚动升级, 原因在于每个实例都有很多的网络连接, 一旦重启, SparkTask就会出现异常, 造成大规模的任务重试, 对集群会产生巨大的压力. 因此只能采用灰度升级方案, 发布也必须支持多版本特性.</p>
<p>每个版本发布包都有一个版本号, 进程启动是会将版本号写入到Zookeeper的元数据之中, 客户端会根据自身的版本号, 选择对应的路径, 然后获取到ShuffleManager的地址, 完成整个任务的启动环境.</p>
<p>所以, 整个客户端/RssManager/RssServer的版本都是配套的. 整套环境之中, 目标最多只能存在3个版本.<br>为了防止用户客户端死活不升级情况, Spark加载版本和jar包方式, 将通过Zookeeper获取元数据, 然后启动的时候, 远程加载配置项和jar文件, 这段代码需要注入到Spark之中, 而非RSS.</p>
<h4 id="部署方案"><a href="#部署方案" class="headerlink" title="部署方案"></a>部署方案</h4><div class="table-container">
<table>
<thead>
<tr>
<th>实例角色</th>
<th>最少个数</th>
<th>推荐个数</th>
<th>部署位置</th>
</tr>
</thead>
<tbody>
<tr>
<td>Zookeeper</td>
<td>3</td>
<td>5</td>
<td>单独节点, 至少独立磁盘</td>
</tr>
<tr>
<td>RssManager</td>
<td>2</td>
<td>2</td>
<td>Master单独一个节点, Slave单独一个节点</td>
</tr>
<tr>
<td>RssServer</td>
<td>5</td>
<td>30</td>
<td>单独节点</td>
</tr>
</tbody>
</table>
</div>
<ol>
<li>每个节点, 对于单个版本, 只部署单个实例</li>
<li>机器尽量在同一机房, 网络带宽尽量大, 因为需要内部传输备份数据</li>
<li>RssManager的资源尽量在8核16G以上, 防止RPC和元数据处理成为集群瓶颈</li>
<li>RssServer机器尽量是SSD盘, 每个节点过挂一些数据盘, 尽量满足1核2G1TB的配置方式</li>
</ol>
<h4 id="升级方案"><a href="#升级方案" class="headerlink" title="升级方案"></a>升级方案</h4><p>整体采用灰度升级方案, 即每个节点会部署多个实例, <code>RssManager</code>和<code>RssServer</code>各自部署一套, 两者元数据分开存储, 但调度器会感知多个版本的任务情况.<br>整体升级步骤如下:</p>
<ol>
<li>部署新版本的<code>RssManager</code>, 在standby的机器上部署另外一个备<code>RssManager</code></li>
<li>逐个安装新的版本的<code>RssServer</code>, 完成后并添加新版本的监控告警</li>
<li>更新新版本客户端到HDFS</li>
<li>更新Zookeeper上最新RSS客户端版本</li>
<li>过两天, 查看老版本的<code>RssManager</code>的负载, 如果任务数已经降低为0, 则准备下线版本</li>
<li>关闭监控告警, 逐个关闭Server, 最后关闭两个Manager.</li>
</ol>
<h5 id="Zookeeper节点切换"><a href="#Zookeeper节点切换" class="headerlink" title="Zookeeper节点切换"></a>Zookeeper节点切换</h5><p>整个集群之中, Zookeeper虽然不是单点的, 但是ZK集群确实单点的, 一旦节点老旧必须替换升级或者IP切换的时候, ZK地址已经变换, RSS和Spark配置都要相对的变化, 这时就必须重启完成, 此时必须<strong>容忍任务大规模重试</strong>.</p>
<h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><h4 id="鉴权"><a href="#鉴权" class="headerlink" title="鉴权"></a>鉴权</h4><p>内部集群可以先不考虑</p>
<h4 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h4><p>Shuffle数据作为临时数据, 用户即可清理, 可以先不做完整性校验(目前Spark也没有做)</p>
<h4 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h4><p>Shuffle数据根据App粒度清理, Yarn Shuffle Service之中, Driver在退出的时候, 会清理对应的数据, 但不删除目录. 目录有Yarn感知到App状态为完成之后, 下发NodeManager完成清理工作.<br>但在Shuffle Service之中, 由于无法感知App状态, 因此需要Driver来主动清理. </p>
<ul>
<li>在Driver退出的过程之中, 会向Manager发送AppEnd的消息, 接收到请求之后, 开始清理App对应的Shuffle, 想各个Service发送完毕异步请求之后, 将App的状态标记为Deleted, 过一段时间后删除该状态</li>
<li>如果Driver异常退出, 度过静默期(无RPC往来的时长)之后ShuffleManager主动查询Yarn上App的状态, 如果为退出状态, 则主动删除数据.</li>
<li>ShuffleManager如果主备切换, 由于App的信息保存在Zookeeper之中, 因此备节点依然会完成清理工作</li>
<li>ShuffleService实例如果发重启, 那么它会主动询问是否有资源未清理, 如果发现本地APP的在状态为Deleted, 或者查询不到.</li>
</ul>
<h3 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h3><h4 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h4><p>资源的类型有以下几类:</p>
<ol>
<li>磁盘容量</li>
<li>内存Buffer量</li>
<li>IO负载压力</li>
<li>CPU负载压力</li>
</ol>
<h4 id="DataLocation"><a href="#DataLocation" class="headerlink" title="DataLocation"></a>DataLocation</h4><p>分配Server节点的时候, 需要返回机架信息, 方便Reduce任务决策启动在哪些几点之上.</p>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><h4 id="支持多磁盘写入"><a href="#支持多磁盘写入" class="headerlink" title="支持多磁盘写入"></a>支持多磁盘写入</h4><p>文件磁盘目录, 也需要根据Spark一样规划为多级目录, 同时支持多个SSD目录<br>文件也会根据AppId + ShuffleId + PartitionId的hash值计算出对应的目录路径</p>
<h4 id="小数据块合并发送"><a href="#小数据块合并发送" class="headerlink" title="小数据块合并发送"></a>小数据块合并发送</h4><p>Map写入, 如果数据块比较小, 且写入同一个Server, 则可以合并发送.</p>
<h4 id="文件流式读取"><a href="#文件流式读取" class="headerlink" title="文件流式读取"></a>文件流式读取</h4><p>对于Reduce任务, 如果Partition实在太大, 可以根据流式方式读取</p>
<h4 id="小数据块合并读取"><a href="#小数据块合并读取" class="headerlink" title="小数据块合并读取"></a>小数据块合并读取</h4><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228172327830.png" alt="image-20220228172327830"><br>例如上图, 在shuffleRead的时候,需要花费近6个小时, 主要原因在于网络小io太多了</p>
<h4 id="2GB限制"><a href="#2GB限制" class="headerlink" title="2GB限制"></a>2GB限制</h4><p>Spark在Shuffle的时候, 已经通过<code>DownloadManager</code>, 通过文件的方式解决了2GB的限制, 但目前这儿依然由这个限制.<br>如何解决问题?  仿照<code>Spark</code>的处理方式, 如果发现数据量大于2GB, 则启动文件发送, 服务端需要重新定义<code>handler</code>, 整个数据也写入到临时文件之中, 不要写在原有RSS的数据文件之中.<br><code>ShuffleDataWrapper</code>需要加入一个新的字段, 或者将<code>data_length</code>设置为负值</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/28/Clickhouse%E7%A0%94%E7%A9%B6-Clickhouse%E7%9A%84%E5%90%8C%E6%AD%A5%E9%94%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/02/28/Clickhouse%E7%A0%94%E7%A9%B6-Clickhouse%E7%9A%84%E5%90%8C%E6%AD%A5%E9%94%81/" class="post-title-link" itemprop="url">[Clickhouse研究]: Clickhouse的同步锁</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 15:28:36" itemprop="dateCreated datePublished" datetime="2022-02-28T15:28:36+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Clickhouse的存储锁"><a href="#Clickhouse的存储锁" class="headerlink" title="Clickhouse的存储锁"></a>Clickhouse的存储锁</h1><h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><p>代码主要在<code>IStorage</code>之中<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">IStorage</span> </span><br><span class="line">&#123;</span><br><span class="line">TableLockHolder lockForShare;</span><br><span class="line">TableLockHolder lockForAlter;</span><br><span class="line">TableExclusiveLockHolder lockExclusively;</span><br><span class="line"><span class="keyword">mutable</span> RWLock alter_lock;</span><br><span class="line"><span class="keyword">mutable</span> RWLock drop_lock;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>从代码的定义上来,  只有drop和alter相关的才会加锁</p>
<p>排它锁<code>lockExclusively</code>的锁同时锁住<code>alter_lock</code>和<code>drop_lock</code>, 锁类型为写锁<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">TableExclusiveLockHolder <span class="title">IStorage::lockExclusively</span><span class="params">(<span class="type">const</span> String &amp; query_id, <span class="type">const</span> std::chrono::milliseconds &amp; acquire_timeout)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    TableExclusiveLockHolder result;</span><br><span class="line">    result.alter_lock = <span class="built_in">tryLockTimed</span>(alter_lock, RWLockImpl::Write, query_id, acquire_timeout);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (is_dropped)</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">Exception</span>(<span class="string">&quot;Table is dropped&quot;</span>, ErrorCodes::TABLE_IS_DROPPED);</span><br><span class="line"></span><br><span class="line">    result.drop_lock = <span class="built_in">tryLockTimed</span>(drop_lock, RWLockImpl::Write, query_id, acquire_timeout);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>排它锁只有很少的地方用到<br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228152910967.png" alt="image-20220228152910967"></p>
<ol>
<li>在renameTable时候用到</li>
<li>在DropTable的时候用到</li>
<li>在restartReplica时候用到</li>
</ol>
<p>修改锁<code>lockForAlter</code>只锁了<code>alter</code>, 锁类型为写锁<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">TableLockHolder <span class="title">IStorage::lockForAlter</span><span class="params">(<span class="type">const</span> String &amp; query_id, <span class="type">const</span> std::chrono::milliseconds &amp; acquire_timeout)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    TableLockHolder result = <span class="built_in">tryLockTimed</span>(alter_lock, RWLockImpl::Write, query_id, acquire_timeout);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (is_dropped)</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">Exception</span>(<span class="string">&quot;Table is dropped&quot;</span>, ErrorCodes::TABLE_IS_DROPPED);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>都只在修改DDL时候用到: DDL语句执行和复制表的同步DDL时<br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228152931062.png" alt="image-20220228152931062"></p>
<p>共享锁<code>lockForShare</code>的锁加入在<code>drop_lock</code>之中, 锁类型为读锁<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">TableLockHolder <span class="title">IStorage::lockForShare</span><span class="params">(<span class="type">const</span> String &amp; query_id, <span class="type">const</span> std::chrono::milliseconds &amp; acquire_timeout)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    TableLockHolder result = <span class="built_in">tryLockTimed</span>(drop_lock, RWLockImpl::Read, query_id, acquire_timeout);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (is_dropped)</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">Exception</span>(<span class="string">&quot;Table is dropped&quot;</span>, ErrorCodes::TABLE_IS_DROPPED);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>共享锁调用的地方非常多, 常见的Insert语句也是排它锁.</p>
<p>根据代码推论:</p>
<ol>
<li>插入过程之中删除插入表, 删除动作会等待插入完成再执行</li>
<li>插入过程之中修改插入表, 表结构能够修改成功</li>
<li>Insert语句锁住整个query执行时间</li>
</ol>
<h2 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h2><h3 id="建表语句"><a href="#建表语句" class="headerlink" title="建表语句"></a>建表语句</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `lineorder_local`</span><br><span class="line">(</span><br><span class="line">    LO_ORDERKEY             UInt32,</span><br><span class="line">    LO_LINENUMBER           UInt8,</span><br><span class="line">    LO_CUSTKEY              UInt32,</span><br><span class="line">    LO_PARTKEY              UInt32,</span><br><span class="line">    LO_SUPPKEY              UInt32,</span><br><span class="line">    LO_ORDERDATE            <span class="type">Date</span>,</span><br><span class="line">    LO_ORDERPRIORITY        LowCardinality(String),</span><br><span class="line">    LO_SHIPPRIORITY         UInt8,</span><br><span class="line">    LO_QUANTITY             UInt8,</span><br><span class="line">    LO_EXTENDEDPRICE        UInt32,</span><br><span class="line">    LO_ORDTOTALPRICE        UInt32,</span><br><span class="line">    LO_DISCOUNT             UInt8,</span><br><span class="line">    LO_REVENUE              UInt32,</span><br><span class="line">    LO_SUPPLYCOST           UInt32,</span><br><span class="line">    LO_TAX                  UInt8,</span><br><span class="line">    LO_COMMITDATE           <span class="type">Date</span>,</span><br><span class="line">    LO_SHIPMODE             LowCardinality(String)</span><br><span class="line">)</span><br><span class="line">ENGINE <span class="operator">=</span> MergeTree</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYear(LO_ORDERDATE) </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (LO_ORDERDATE, LO_ORDERKEY);</span><br></pre></td></tr></table></figure>
<h3 id="插入语句"><a href="#插入语句" class="headerlink" title="插入语句"></a>插入语句</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.<span class="operator">/</span>clickhouse<span class="operator">-</span>client  <span class="comment">--query &quot;INSERT INTO hzw.lineorder_local FORMAT CSV&quot; &lt; lineorder.tbl</span></span><br></pre></td></tr></table></figure>
<h3 id="插入过程之中删除插入表"><a href="#插入过程之中删除插入表" class="headerlink" title="插入过程之中删除插入表"></a>插入过程之中删除插入表</h3><p>删除表语句<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> lineorder_local;</span><br></pre></td></tr></table></figure><br><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228152954941.png" alt="image-20220228152954941"></p>
<p>出现无法获取锁的问题</p>
<h3 id="插入过程之中修改插入表"><a href="#插入过程之中修改插入表" class="headerlink" title="插入过程之中修改插入表"></a>插入过程之中修改插入表</h3><p> 修改表语句<br> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> lineorder_local <span class="keyword">drop</span> <span class="keyword">column</span> LO_QUANTITY;</span><br></pre></td></tr></table></figure><br> 执行后, 会立马成功<br> <img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228153018786.png" alt="image-20220228153018786"></p>
<p>由于乱序执行, 测试一个更加夸张的例子<br> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> lineorder_local <span class="keyword">delete</span> <span class="keyword">where</span> <span class="number">1</span><span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure><br> <img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220228153033588.png" alt="image-20220228153033588"><br> 这里alter立马会成功, 数据会删除, 但是insert还在继续.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/28/Clickhouse%E7%A0%94%E7%A9%B6-Clickhouse%E7%9A%84WAL%E5%8A%9F%E8%83%BD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/02/28/Clickhouse%E7%A0%94%E7%A9%B6-Clickhouse%E7%9A%84WAL%E5%8A%9F%E8%83%BD/" class="post-title-link" itemprop="url">[Clickhouse研究]: Clickhouse的WAL功能</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-28 15:07:16" itemprop="dateCreated datePublished" datetime="2022-02-28T15:07:16+08:00">2022-02-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Clickhouse的WAL功能"><a href="#Clickhouse的WAL功能" class="headerlink" title="Clickhouse的WAL功能"></a>Clickhouse的WAL功能</h1><h2 id="设计目的"><a href="#设计目的" class="headerlink" title="设计目的"></a>设计目的</h2><p>解决小批量数据写入时, 频繁写入dataPart, 导致磁盘繁忙的问题或者出现<code>DB::Exception: Too many parts</code></p>
<p>具体可以参考这篇<a href="https://bohutang.me/2020/08/18/clickhouse-and-friends-merge-tree-wal/">文档</a></p>
<blockquote>
<p>并非binlog的模式, 数据flush后, 会清理wal文件</p>
</blockquote>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>首先看写逻辑的入口, 在<code>MergeTreeDataWriter::writeTempPart</code>创建了一个<code>MergeTreeData::MutableDataPartPtr</code>的类型<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">MergeTreeData::MutableDataPartPtr <span class="title">MergeTreeDataWriter::writeTempPart</span><span class="params">(BlockWithPartition &amp; block_with_partition, <span class="type">const</span> StorageMetadataPtr &amp; metadata_snapshot)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">auto</span> new_data_part = data.<span class="built_in">createPart</span>(</span><br><span class="line">        part_name,</span><br><span class="line">        data.<span class="built_in">choosePartType</span>(expected_size, block.<span class="built_in">rows</span>()),</span><br><span class="line">        new_part_info,</span><br><span class="line">        <span class="built_in">createVolumeFromReservation</span>(reservation, volume),</span><br><span class="line">        TMP_PREFIX + part_name);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><code>MergeTreeData::MutableDataPartPtr</code>有三种实现, <code>IN_MEMORY</code>是写入到内存中, 由于内存是易失的, 所以需要WAL功能的辅助.<code>COMPACT</code>和<code>WIDE</code>都是文件存储, 但文件编码和压缩方式不同.<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">MergeTreeData::MutableDataPartPtr <span class="title">MergeTreeData::createPart</span><span class="params">(<span class="type">const</span> String &amp; name,</span></span></span><br><span class="line"><span class="params"><span class="function">    MergeTreeDataPartType type, <span class="type">const</span> MergeTreePartInfo &amp; part_info,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> VolumePtr &amp; volume, <span class="type">const</span> String &amp; relative_path)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (type == MergeTreeDataPartType::COMPACT)</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;MergeTreeDataPartCompact&gt;(*<span class="keyword">this</span>, name, part_info, volume, relative_path);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (type == MergeTreeDataPartType::WIDE)</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;MergeTreeDataPartWide&gt;(*<span class="keyword">this</span>, name, part_info, volume, relative_path);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (type == MergeTreeDataPartType::IN_MEMORY)</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;MergeTreeDataPartInMemory&gt;(*<span class="keyword">this</span>, name, part_info, volume, relative_path);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">Exception</span>(<span class="string">&quot;Unknown type of part &quot;</span> + relative_path, ErrorCodes::UNKNOWN_PART_TYPE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>上面的逻辑, 主要是根据<code>MergeTreeDataPartType</code>的类型选择, 那么我们看一下, 上面什么时候会选择该类型: 当part的文件小于<code>min_bytes_for_compact_part</code>或者行数小于<code>min_rows_for_compact_part</code>, 只要满足一种一项即可.<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">MergeTreeDataPartType <span class="title">MergeTreeData::choosePartType</span><span class="params">(<span class="type">size_t</span> bytes_uncompressed, <span class="type">size_t</span> rows_count)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> settings = <span class="built_in">getSettings</span>();</span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">canUsePolymorphicParts</span>(*settings))</span><br><span class="line">        <span class="keyword">return</span> MergeTreeDataPartType::WIDE;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (bytes_uncompressed &lt; settings-&gt;min_bytes_for_compact_part || rows_count &lt; settings-&gt;min_rows_for_compact_part)</span><br><span class="line">        <span class="keyword">return</span> MergeTreeDataPartType::IN_MEMORY;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (bytes_uncompressed &lt; settings-&gt;min_bytes_for_wide_part || rows_count &lt; settings-&gt;min_rows_for_wide_part)</span><br><span class="line">        <span class="keyword">return</span> MergeTreeDataPartType::COMPACT;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MergeTreeDataPartType::WIDE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>那么回过头来看<code>MergeTreeDataPartInMemory</code>的实现</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MergeTreeDataPartInMemory</span> : <span class="keyword">public</span> IMergeTreeDataPart</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// 忽略部分函数</span></span><br><span class="line">  <span class="keyword">mutable</span> Block block;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从源码上看, <code>MergeTreeDataPartInMemory</code>就是原本Block写入本地磁盘, 而它则放入到内存中. </p>
<p>那么如果进程重启, 内存中数据丢失后, 该如何处理呢?</p>
<p>答案在于<code>MergeTreeWriteAheadLog</code>的功能中, 将用户数据写入到WAL.</p>
<p>当进程启动的时候, 会调用<code>restore</code>从WAL的文件中, 将数据恢复到内存中</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">MergeTreeData::MutableDataPartsVector <span class="title">MergeTreeWriteAheadLog::restore</span><span class="params">(<span class="type">const</span> StorageMetadataPtr &amp; metadata_snapshot)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span> (action_type == ActionType::ADD_PART)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">auto</span> part_disk = storage.<span class="built_in">reserveSpace</span>(<span class="number">0</span>)-&gt;<span class="built_in">getDisk</span>();</span><br><span class="line">                <span class="keyword">auto</span> single_disk_volume = std::<span class="built_in">make_shared</span>&lt;SingleDiskVolume&gt;(<span class="string">&quot;volume_&quot;</span> + part_name, disk);</span><br><span class="line"></span><br><span class="line">                part = storage.<span class="built_in">createPart</span>(</span><br><span class="line">                    part_name,</span><br><span class="line">                    MergeTreeDataPartType::IN_MEMORY,</span><br><span class="line">                    MergeTreePartInfo::<span class="built_in">fromPartName</span>(part_name, storage.format_version),</span><br><span class="line">                    single_disk_volume,</span><br><span class="line">                    part_name);</span><br><span class="line"></span><br><span class="line">                block = block_in.<span class="built_in">read</span>();</span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么wal文件会越写越多, 什么时候会开始清理部分数据呢?</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">MergeTreeWriteAheadLog::addPart</span><span class="params">(<span class="type">const</span> Block &amp; block, <span class="type">const</span> String &amp; part_name)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 写数据到WAL</span></span><br><span class="line">    block_out-&gt;<span class="built_in">write</span>(block);</span><br><span class="line">    block_out-&gt;<span class="built_in">flush</span>();</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">auto</span> max_wal_bytes = storage.<span class="built_in">getSettings</span>()-&gt;write_ahead_log_max_bytes;</span><br><span class="line">    <span class="keyword">if</span> (out-&gt;<span class="built_in">count</span>() &gt; max_wal_bytes)</span><br><span class="line">        <span class="built_in">rotate</span>(lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>addPart</code>的逻辑之中, 会检查WAL文件的大小, 当文件大于<code>write_ahead_log_max_bytes</code>(默认为1GB)时, 开始清理WAL文件</p>
<p>另外一个问题, <strong>WAL的内存部分数据存放在哪儿</strong>, 在insert的时候(<code>renameTempPartAndReplace</code>), 数据会放到<code>data_parts_indexes.insert</code>之中, read时候从这里读取数据</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">MergeTreeData::renameTempPartAndReplace</span><br><span class="line">&#123;</span><br><span class="line">    part-&gt;name = part_name;</span><br><span class="line">    part-&gt;info = part_info;</span><br><span class="line">    part-&gt;is_temp = <span class="literal">false</span>;</span><br><span class="line">    part-&gt;state = DataPartState::PreCommitted;</span><br><span class="line">    part-&gt;<span class="built_in">renameTo</span>(part_name, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> part_it = data_parts_indexes.<span class="built_in">insert</span>(part).first;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>数据恢复的时候, <code>loadDataParts</code>的时候, 数据被读取出来, 然后插入到<code>data_parts_indexes</code>之中, 通过<code>getActiveContainingPart</code>过滤重复的数据<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">MergeTreeData::loadDataParts</span><br><span class="line">&#123;</span><br><span class="line">    for (auto &amp; part : parts_from_wal)</span><br><span class="line">   &#123;</span><br><span class="line">       if (getActiveContainingPart(part-&gt;info, DataPartState::Committed, part_lock))</span><br><span class="line">           continue;</span><br><span class="line"></span><br><span class="line">       part-&gt;modification_time = time(nullptr);</span><br><span class="line">       /// Assume that all parts are Committed, covered parts will be detected and marked as Outdated later</span><br><span class="line">       part-&gt;state = DataPartState::Committed;</span><br><span class="line"></span><br><span class="line">       if (!data_parts_indexes.insert(part).second)</span><br><span class="line">           throw Exception(&quot;Part &quot; + part-&gt;name + &quot; already exists&quot;, ErrorCodes::DUPLICATE_DATA_PART);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到Clickhouse的WAL机制, 并没有RocksDB的那种MemTable, 因此两个批次的数据, 并不会在内存中合并. </p>
<p>所有的合并操作, 依然由后台线程来处理,  支持在合并的流程中, 抽象为2个DataPart的合并, 但实际上可以是一个InMem的DP和一个OnDisk的DP做合并.</p>
<p>Clickhouse的合并后的数据都写入到磁盘中.</p>
<p>另外一个点, 在复制表中, InMem的DP依然会做同步.</p>
<p>在<code>DataPartsExchange</code>有两个函数<code>sendPartFromMemory</code>和<code>downloadPartToMemory</code>, 前者用于发送数据, 后者用户下载数据, 同步后, 数据依然是InMem格式.</p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>创建一张表, 指定<code>min_rows_for_compact_part</code>为200,write_ahead_log_max_bytes为8192(8K)<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> default.lineorder_local1</span><br><span class="line">(</span><br><span class="line">    `LO_ORDERKEY` UInt32,</span><br><span class="line">    `LO_LINENUMBER` UInt8,</span><br><span class="line">    `LO_CUSTKEY` UInt32,</span><br><span class="line">    `LO_PARTKEY` UInt32,</span><br><span class="line">    `LO_SUPPKEY` UInt32,</span><br><span class="line">    `LO_ORDERDATE` <span class="type">Date</span>,</span><br><span class="line">    `LO_ORDERPRIORITY` LowCardinality(String),</span><br><span class="line">    `LO_SHIPPRIORITY` UInt8,</span><br><span class="line">    `LO_QUANTITY` UInt8,</span><br><span class="line">    `LO_EXTENDEDPRICE` UInt32,</span><br><span class="line">    `LO_ORDTOTALPRICE` UInt32,</span><br><span class="line">    `LO_DISCOUNT` UInt8,</span><br><span class="line">    `LO_REVENUE` UInt32,</span><br><span class="line">    `LO_SUPPLYCOST` UInt32,</span><br><span class="line">    `LO_TAX` UInt8,</span><br><span class="line">    `LO_COMMITDATE` <span class="type">Date</span>,</span><br><span class="line">    `LO_SHIPMODE` LowCardinality(String)</span><br><span class="line">)</span><br><span class="line">ENGINE <span class="operator">=</span> MergeTree</span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> toYear(LO_ORDERDATE)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (LO_ORDERDATE, LO_ORDERKEY)</span><br><span class="line">SETTINGS index_granularity <span class="operator">=</span> <span class="number">8192</span>, min_rows_for_compact_part <span class="operator">=</span> <span class="number">200</span>,write_ahead_log_max_bytes<span class="operator">=</span><span class="number">8192</span>;</span><br></pre></td></tr></table></figure></p>
<p>插入100条数据<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> lineorder_local1 <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> lineorder_local limit <span class="number">100</span>;</span><br></pre></td></tr></table></figure></p>
<p>查看数据目录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-nmg-client01.nmg01 /var/lib/clickhouse/data/default/lineorder_local1]$ ll</span><br><span class="line">total 12</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse    6 Apr 12 14:53 detached</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse    1 Apr 12 14:53 format_version.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 4766 Apr 12 14:54 wal.bin</span><br></pre></td></tr></table></figure><br>出现了一个<code>wal.bin</code>的文件<br>再插入一次, 发现又出现了一个bin文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-nmg-client01.nmg01 /var/lib/clickhouse/data/default/lineorder_local1]$ ll</span><br><span class="line">total 16</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse   10 Apr 12 15:18 detached</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse    1 Apr 12 15:18 format_version.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 9532 Apr 12 15:18 wal_1_2.bin</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse    0 Apr 12 15:18 wal.bin</span><br></pre></td></tr></table></figure></p>
<p>多了一个<code>wal_1_2.bin</code>的文件, 我们在多插入几次, 到第5次插入的时候, 会生成一个datapart<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-nmg-client01.nmg01 /var/lib/clickhouse/data/default/lineorder_local1]$ ll</span><br><span class="line">total 40</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 Apr 12 15:39 1992_1_5_1</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse   10 Apr 12 15:18 detached</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse    1 Apr 12 15:18 format_version.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 9532 Apr 12 15:18 wal_1_2.bin</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 9532 Apr 12 15:26 wal_3_4.bin</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 4766 Apr 12 15:39 wal.bin</span><br></pre></td></tr></table></figure><br>再过一段时间观察, 发现<code>wal_*_*.bin</code>文件已经被删除了, 原因在于data_part已经commit的了<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-nmg-client01.nmg01 /var/lib/clickhouse/data/default/lineorder_local1]$ ll</span><br><span class="line">total 16</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse 4096 Apr 12 15:39 1992_1_5_1</span><br><span class="line">drwxr-x--- 2 clickhouse clickhouse   10 Apr 12 15:18 detached</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse    1 Apr 12 15:18 format_version.txt</span><br><span class="line">-rw-r----- 1 clickhouse clickhouse 4766 Apr 12 15:39 wal.bin</span><br><span class="line">[root@bigdata-nmg-client01.nmg01 /var/lib/clickhouse/data/default/lineorder_local1]$</span><br></pre></td></tr></table></figure></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/27/Clickhouse%E9%97%AE%E9%A2%98-%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE%E5%88%9D%E5%A7%8B%E5%8C%96%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/02/27/Clickhouse%E9%97%AE%E9%A2%98-%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE%E5%88%9D%E5%A7%8B%E5%8C%96%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/" class="post-title-link" itemprop="url">[Clickhouse问题]: 物化视图初始化数据丢失与重复问题</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-27 11:37:16" itemprop="dateCreated datePublished" datetime="2022-02-27T11:37:16+08:00">2022-02-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h2><p>现在CK创建视图有2种初始化数据的方式</p>
<ol>
<li><p>在 CREATE 语句中带上 polulate 关键字，会将执行时间点之前的底表的历史数据全部初始化到视图中。执行完成后的底表新数据也会进视图，但是执行过程中的<strong>数据会丢失</strong>；</p>
</li>
<li><p>在 CREATE 语句中不带 polulate 关键字，会将执行完成后的底表新数据会进视图，但是执行完成之前的数据都不会进视图；如果而后手工执行insert命令, 导入历史数据, 那么<strong>重复数据</strong></p>
</li>
</ol>
<h2 id="Polulate数据丢失"><a href="#Polulate数据丢失" class="headerlink" title="Polulate数据丢失"></a>Polulate数据丢失</h2><h3 id="根因分析"><a href="#根因分析" class="headerlink" title="根因分析"></a>根因分析</h3><p>先明晰一下MV更新的时候的时序图</p>
<p>下图中有4个角色: <strong>插入语句执行者, 底表插入数据执行者, MV1插入数据执行者, MV2创建语句执行者</strong> </p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220227113952566.png" alt="image-20220227113952566"></p>
<p>首先, 对于底表来说, 第一批写开始时, 因为MV2并没有被创建, 因此对于它来说, 只会给MV1主动推送数据, 相当于这批次的数据全部丢失了.</p>
<p>其次, 对于MV2创建来说, 由于带有populate字段, 他会主动去拉取历史数据, 但是由于底表没有全部写完, 只写了DP1, 那么DP2和DP3的数据就丢失了.</p>
<p>因此, 总结来说, <strong>在插入过程之中创建底表会丢失的数据是, 在底表里DataPart没有写完的那些数据, 写完的数据还是会被读取的.</strong></p>
<p>最后, 看第二批写的情况, 由于检查MV的时候, MV1和MV2已经存在(虽然这个时候, 创建MV2的语句被没有结束, 但是由于CK没有一致性保证, 所以元数据的信息可以被外面捕获到), 此时第二批次的数据, 在正常情况下能够推送给MV2.</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>利用存储的锁机制, 在插入时禁止populate操作</p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220227114132890.png" alt="image-20220227114132890"></p>
<ol>
<li>写入时, 加入写入的共享锁, 可以支持同时插入到一个数据表中</li>
<li>执行create table的元数据创建时, 获取底表的排它锁, 如图中所示, 此时正好在插入, 则会等待插入执行完毕后, 再进场元数据操作</li>
<li>元数据执行完毕后立即释放锁, 耗时的populate阶段, 是无锁状态. 因此第二次插入, 只需要等待极小的一个时间即可执行数据插入动作.</li>
</ol>
<blockquote>
<p><strong>使用限制</strong></p>
<p>目前如果有大型insert的操作的话, 此时会无法完成基于底表的创建视图操作</p>
</blockquote>
<h3 id="复制表问题"><a href="#复制表问题" class="headerlink" title="复制表问题"></a>复制表问题</h3><p>目前视图使用create view to table的方式建立的, 如果视图里面带有populate, 就会出现MV多数据的情况, 原因如下图所示</p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220227114313082.png" alt="image-20220227114313082"></p>
<p><strong>解决方案</strong></p>
<p>只允许一个节点写入, 跟DLAP-Manager交流, 目前复制表只有一个节点可写, 符合预期</p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/image-20220227114345189.png" alt="image-20220227114345189"></p>
<p>从上面的分析来看, 整体物化视图的初始化, 比较合适构建在<strong>外部的Manager</strong>中. 但此时就需要处理场景2中数据重复的问题</p>
<h2 id="Insert数据重复"><a href="#Insert数据重复" class="headerlink" title="Insert数据重复"></a>Insert数据重复</h2><p>Insert数据重复比较好了解, 因为是人工操作, 因此创建完毕物化视图, 和执行insert命令期间, 有可能已经有一些批次的数据写入到物化视图中, 如果此时导入全部的历史数据, 那么数据就会出现重复的情况.</p>
<blockquote>
<p>去重视图一般不影响, 但如果是聚合是视图, 那么结果将不正确.</p>
</blockquote>
<h3 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h3><p>数据快照</p>
<h2 id="大底表的处理方案"><a href="#大底表的处理方案" class="headerlink" title="大底表的处理方案"></a>大底表的处理方案</h2><ol>
<li><p>创建视图时, 获取底表所有的分区</p>
</li>
<li><p>通过参数设置并发, 创建并发个数的临时表</p>
</li>
<li><p>按照分区修改插入语句, 此时引擎测需要保证: 该表达式能够完成分区裁剪, 并在实际执行时忽略掉判断(这是一个难点)</p>
<p>where splitByChar(‘<em>‘,_part)[1]=’1993’ and toInt32(splitByChar(‘</em>‘,_part)[3]) &lt; 500</p>
</li>
<li><p>临时表的插入, 只能有一个并发. 插入完毕后, 用attach parition的方式, 将分区加入到物化视图的底表中, 然后删除临时表, 再重新创建一个临时, 开启下一轮操作.</p>
</li>
<li><p>如果插入临时表时候, 系统需要自动清空(或者删除重建)临时表, 并重试. 如果attach时失败, 则返回异常, 由用户删除物化视图, 并开始重建工作.</p>
</li>
<li><p>期间Clickhouse Server节点如果出现异常, 则整个任务失败. 如果DLAP-Manager出现重启, 则可以继续redo整个任务.</p>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/01/28/SparkSQL-%E5%B0%8F%E6%96%87%E4%BB%B6%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/01/28/SparkSQL-%E5%B0%8F%E6%96%87%E4%BB%B6%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/" class="post-title-link" itemprop="url">SparkSQL: 小文件的处理方式</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-28 11:24:38" itemprop="dateCreated datePublished" datetime="2022-01-28T11:24:38+08:00">2022-01-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="自适应执行"><a href="#自适应执行" class="headerlink" title="自适应执行"></a>自适应执行</h2><p>社区在Spark2.3版本之后的AdaptiveExecute特性之中就能很好的解决Partition个数过多导致小文件过多的问题.<br>通过动态的评估Shuffle输入的个数(通过设置<code>spark.sql.adaptive.shuffle.targetPostShuffleInputSize</code>实现), 可以聚合多个Task任务, 减少Reduce的个数<br>使用方式:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> spark.sql.adaptive.enabled<span class="operator">=</span><span class="literal">true</span></span><br><span class="line"><span class="keyword">set</span> spark.sql.adaptive.shuffle.targetPostShuffleInputSize<span class="operator">=</span><span class="number">128</span>MB</span><br></pre></td></tr></table></figure><br>优点:</p>
<ul>
<li>自动根据任务的数据量进行聚合</li>
</ul>
<p>缺点:</p>
<ul>
<li>必须存在Shuffle过程, 否则不生效</li>
<li>任务的Shuffle输出比不能太低</li>
</ul>
<blockquote>
<p>Shuffle输出比, 为一个Shuffle任务中最后Output的数据量除以ShuffleRead的数据量的数值. 如果ShuffleRead为100GB, 而输出为1GB, 那么Shuffle输出比为1%. 如果这值比较低, 说明Task之中有很高强度的Filter功能. 这个数值太低会对系统产生比较大影响, 例如每个Shuffle块为<code>128MB</code>, 如果输出比为10%, 那么最后在HDFS之中只有<code>12.8MB</code>, 就如会出现小文件问题. 因此动态执行功能并不会对此产生太大的效果. 现实中, 由于SparkSQL已经有比较高效的<code>FilterPushDown</code>功能, 因此这个比例不太太高, 在在20%以上.</p>
</blockquote>
<h2 id="HINT方式"><a href="#HINT方式" class="headerlink" title="HINT方式"></a>HINT方式</h2><p>社区在Spark2.4版本之后引入HINT模式<a href="https://issues.apache.org/jira/browse/SPARK-24940">SPARK-24940</a>, 可以由用户来指定最后分区的个数, 只要在SQL语句之中加入注释文件<br>使用方式:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> ... <span class="keyword">SELECT</span> <span class="comment">/*+ COALESCE(numPartitions) */</span> ...</span><br><span class="line"><span class="keyword">INSERT</span> ... <span class="keyword">SELECT</span> <span class="comment">/*+ REPARTITION(numPartitions) */</span> ...</span><br></pre></td></tr></table></figure><br>优点:</p>
<ul>
<li>支持简单无Shuffle模式的Reparation</li>
</ul>
<p>缺点:</p>
<ul>
<li>需要人工干预, 设计Partition的个数, 而对于变化的场景来说, 难有一个固定的Partition个数</li>
<li>无法处理Shuffle输出比过低的场景</li>
</ul>
<h2 id="独立的小文件合并"><a href="#独立的小文件合并" class="headerlink" title="独立的小文件合并"></a>独立的小文件合并</h2><p>综上所诉两个方案都无法处理Shuffle输出比过低的场景, 因此我们需要一种兜底方案: 直接读取HDFS上的数据, 进行合并操作.<br>当插入任务完成之后, 新启动一个Job读取所有的数据, 然后根据设置的文件大小, 进行合并并会写到HDFS之中.<br>由于是直读直写的方式, 因此对于数据大小的评估是非常精确的, 因此可以很好的避免Shuffle输出比的问题.</p>
<p>优点:</p>
<ul>
<li>基本解决了小文件问题</li>
</ul>
<p>缺点:</p>
<ul>
<li>引入新的一次Job过程, 性能会受影响, 特别对中型任务会有一定的影响(10秒左右)</li>
</ul>
<p>使用方式:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> spark.sql.merge.enabled<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> spark.sql.merge.size.per.task<span class="operator">=</span><span class="number">134217728</span>; <span class="comment">--128 * 1024 * 1024 bytes</span></span><br></pre></td></tr></table></figure><br>性能优化:<br>ORC和Parquet格式支持按行读取和按Stripe读取, Stripe读取可以认为是GroupRead, 由于不需要解析文件里面具体的数值, 因此可以按照Stripe粒度读取文件, 再写入文件之中, 以Stripe粒度合并文件.<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> spark.sql.merge.mode<span class="operator">=</span>fast; <span class="comment">-- 默认是pretty, 是逐行读写文件的, 性能较慢</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>实际上说, 这种方式与启动独立合并的任务, 后台不停的合并是一样的, 只不过将这种插入到每个SQL任务中, 并自动完成了</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/12/25/OLAP%E5%AD%A6%E4%B9%A0-%E6%95%B0%E5%AD%A6%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/12/25/OLAP%E5%AD%A6%E4%B9%A0-%E6%95%B0%E5%AD%A6%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">OLAP学习: 数学算法汇总</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-12-25 09:32:20" itemprop="dateCreated datePublished" datetime="2021-12-25T09:32:20+08:00">2021-12-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>900</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="基数估计"><a href="#基数估计" class="headerlink" title="基数估计"></a>基数估计</h2><p>通俗的话来讲, 就是求<code>count distinct</code>,  在公司内部有大量UV场景, 因此一款数据库对<code>基数估计</code>的支持是一个非常重要的功能.</p>
<p>一般计算基数, 通过分布式构造Hash表, 进行group by求解, 但该方式非常消耗内存和CPU, 无法满足大型互联网的要求, 因此有以下两个优化方向. </p>
<h3 id="Bitmap"><a href="#Bitmap" class="headerlink" title="Bitmap"></a>Bitmap</h3><p>对于Long/Int型数据, 可以通过Bitmap方式来求解. Bitmap的存储和计算效率会明显优于Hash表.</p>
<p>普通的Bitmap结构比较清晰,  这里简单讲一下Roaring Bitmaps.</p>
<p>普通的bitmap为一个巨型数组, 而Roaring Bitmap会分为2级结构, 一级分桶, 总共有65535个(short最大值), 每个桶内则是short类型的bitmap, 可以存储65535个字节.</p>
<p>对于一个4字节的Int类型, 会分别取高16位和低16位, 也就是一个Int分裂为2个short类型.</p>
<p>前一个short表示index, 索引到具体的桶内, 后一个short在桶内的bitmap中操作.</p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/20211225095438.png" alt=""></p>
<p>short类型的bitmap有三种类型:</p>
<ol>
<li>array[short]类型</li>
<li>普通bitmap类型</li>
<li>RunLength类型</li>
</ol>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/4a6c83760984e3aa562432eeae79b399.png" alt="img"></p>
<p>对于String类型数据, 可以通过一个KV字典, 将String转化为Int后再行求解.</p>
<h3 id="HLL"><a href="#HLL" class="headerlink" title="HLL"></a>HLL</h3><p>以上面方法不同, HLL是一种<strong>近似计算</strong>基数的方式, 它是基于以下概率论的假设</p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/82d51483cf2d377d799903748adf5f54.png" alt="img"></p>
<p>在真实求解的时候, HLL构造一个桶列表(byte类型, 图中是64个), 取hash值后6位(64=2^6), 索引对应的桶位置, 然后取第一个除首位1之外1的值,  最后将所有桶的数值, 求取调和平均数. (图中Loglog算法为算数平均数, 误差较大)</p>
<p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/v2-db5df7bf6a2222ecbdf4f1c6ba357595_1440w.jpg" alt="img"></p>
<h2 id="百分数"><a href="#百分数" class="headerlink" title="百分数"></a>百分数</h2><h3 id="T-Digest"><a href="#T-Digest" class="headerlink" title="T-Digest"></a>T-Digest</h3><p>准确说tdigest并非是百分数计算方法, 而是一种<strong>抽样方式</strong>, 通过引入质心的概念, 完成类似于KNN聚类效果. </p>
<p>聚类之后, 数据量比原来会小很多,  然后再调用精确计算百分位的函数<code>quantile</code>进行计算.</p>
<p>T-Digest有两种方式, 一种称为<code>buffer and merge</code>, 另一种称为<code>cluster</code>, 整个算法过程主要在平衡误差和计算效率的结果.</p>
<p>具体算法就不学习了, 有需要时, 再来看这个<a href="https://blog.bcmeng.com/pdf/TDigest.pdf">pdf</a> </p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="BloomFilter"><a href="#BloomFilter" class="headerlink" title="BloomFilter"></a>BloomFilter</h3><p><img src="https://carlmartin-pic-1305764798.cos.ap-chengdu.myqcloud.com/img/3.7.1.png" alt="bloomfilter"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/12/12/OLAP%E5%AD%A6%E4%B9%A0-%E5%88%97%E5%AD%98%E7%B3%BB%E7%BB%9F%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Carlmartin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Carlmartin' Blog">
      <meta itemprop="description" content="A place for codeing break.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Carlmartin' Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/12/12/OLAP%E5%AD%A6%E4%B9%A0-%E5%88%97%E5%AD%98%E7%B3%BB%E7%BB%9F%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">OLAP学习: 列存系统汇总</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-12-12 14:20:06" itemprop="dateCreated datePublished" datetime="2021-12-12T14:20:06+08:00">2021-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-06 16:19:03" itemprop="dateModified" datetime="2024-03-06T16:19:03+08:00">2024-03-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/" itemprop="url" rel="index"><span itemprop="name">技术文章</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>142</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="OLAP系统"><a href="#OLAP系统" class="headerlink" title="OLAP系统"></a>OLAP系统</h2><h3 id="开源系统"><a href="#开源系统" class="headerlink" title="开源系统"></a>开源系统</h3><h4 id="Clickhouse"><a href="#Clickhouse" class="headerlink" title="Clickhouse"></a>Clickhouse</h4><h4 id="StarRocks-Doris"><a href="#StarRocks-Doris" class="headerlink" title="StarRocks/Doris"></a>StarRocks/Doris</h4><h4 id="Impala-Kudu"><a href="#Impala-Kudu" class="headerlink" title="Impala/Kudu"></a>Impala/Kudu</h4><h4 id="Greenplum"><a href="#Greenplum" class="headerlink" title="Greenplum"></a>Greenplum</h4><h4 id="Druid"><a href="#Druid" class="headerlink" title="Druid"></a>Druid</h4><h4 id="Presto"><a href="#Presto" class="headerlink" title="Presto"></a>Presto</h4><h3 id="商业软件"><a href="#商业软件" class="headerlink" title="商业软件"></a>商业软件</h3><h4 id="AnalysisDatabase"><a href="#AnalysisDatabase" class="headerlink" title="AnalysisDatabase"></a>AnalysisDatabase</h4><h4 id="SQL-Server"><a href="#SQL-Server" class="headerlink" title="SQL Server"></a>SQL Server</h4><p><a href="https://dl.acm.org/doi/10.1145/1989323.1989448">2011</a></p>
<p><a href="https://dl.acm.org/doi/10.1145/2463676.2463708">2013</a></p>
<p><a href="https://dl.acm.org/doi/10.14778/2824032.2824071">2015</a></p>
<h4 id="TiFlash"><a href="#TiFlash" class="headerlink" title="TiFlash"></a>TiFlash</h4><p><a href="https://www.vldb.org/pvldb/vol13/p3072-huang.pdf">论文</a></p>
<h4 id="Oracle"><a href="#Oracle" class="headerlink" title="Oracle"></a>Oracle</h4><p><a href="https://ieeexplore.ieee.org/document/7113373">论文</a></p>
<p><a href="https://www.oracle.com/technetwork/database/in-memory/overview/twp-oracle-database-in-memory-2245633.pdf">Oracle19c</a></p>
<h4 id="SAP-HANA"><a href="#SAP-HANA" class="headerlink" title="SAP HANA"></a>SAP HANA</h4><p><a href="https://15799.courses.cs.cmu.edu/fall2013/static/papers/p731-sikka.pdf">论文</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Carlmartin</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">186k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">2:49</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
